<!DOCTYPE html>
<html lang="en"><head>
<script src="ShortCourse_files/libs/clipboard/clipboard.min.js"></script>
<script src="ShortCourse_files/libs/quarto-html/tabby.min.js"></script>
<script src="ShortCourse_files/libs/quarto-html/popper.min.js"></script>
<script src="ShortCourse_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="ShortCourse_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ShortCourse_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="ShortCourse_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.269">

  <meta name="author" content="Philipp Otto">
  <title>Short Course</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="ShortCourse_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="ShortCourse_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="ShortCourse_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="ShortCourse_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="ShortCourse_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="ShortCourse_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="ShortCourse_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="ShortCourse_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="ShortCourse_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Short Course</h1>
  <p class="subtitle">Regularised Estimation Procedures in Spatiotemporal Statistics</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Philipp Otto 
</div>
        <p class="quarto-title-affiliation">
            Leibniz University Hannover
          </p>
    </div>
</div>

</section>
<section>
<section id="motivation" class="title-slide slide level1 center" data-number="1">
<h1><span class="header-section-number">1</span> Motivation</h1>

</section>
<section class="slide level2">


<img data-src="figs/hel5.png" class="r-stretch quarto-figure-center"><p class="caption">Cyclists in the city centre of Helsinki (https://ecf.com/news-and-events/news/visionarycities-series-will-helsinki-be-next-cycling-capital)</p></section>
<section id="section" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb1-1" class="hljs-ln-code"><a href="#cb1-1"></a><span class="fu">library</span>(<span class="st">"R.matlab"</span>)</span>
<span id="cb1-2" class="hljs-ln-code"><a href="#cb1-2"></a></span>
<span id="cb1-3" class="hljs-ln-code"><a href="#cb1-3"></a><span class="co"># Bike data</span></span>
<span id="cb1-4" class="hljs-ln-code"><a href="#cb1-4"></a>bikes <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"bikedata.mat"</span>)</span>
<span id="cb1-5" class="hljs-ln-code"><a href="#cb1-5"></a>bikes <span class="ot">&lt;-</span> bikes<span class="sc">$</span>bikes</span>
<span id="cb1-6" class="hljs-ln-code"><a href="#cb1-6"></a></span>
<span id="cb1-7" class="hljs-ln-code"><a href="#cb1-7"></a><span class="co"># Time points and coordinates</span></span>
<span id="cb1-8" class="hljs-ln-code"><a href="#cb1-8"></a></span>
<span id="cb1-9" class="hljs-ln-code"><a href="#cb1-9"></a><span class="co"># Distance matrix</span></span>
<span id="cb1-10" class="hljs-ln-code"><a href="#cb1-10"></a></span>
<span id="cb1-11" class="hljs-ln-code"><a href="#cb1-11"></a><span class="co"># Average bikes per station</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-1" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb2-1" class="hljs-ln-code"><a href="#cb2-1"></a><span class="fu">library</span>(<span class="st">"R.matlab"</span>)</span>
<span id="cb2-2" class="hljs-ln-code"><a href="#cb2-2"></a></span>
<span id="cb2-3" class="hljs-ln-code"><a href="#cb2-3"></a><span class="co"># Bike data</span></span>
<span id="cb2-4" class="hljs-ln-code"><a href="#cb2-4"></a>bikes <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"bikedata.mat"</span>)</span>
<span id="cb2-5" class="hljs-ln-code"><a href="#cb2-5"></a>bikes <span class="ot">&lt;-</span> bikes<span class="sc">$</span>bikes</span>
<span id="cb2-6" class="hljs-ln-code"><a href="#cb2-6"></a></span>
<span id="cb2-7" class="hljs-ln-code"><a href="#cb2-7"></a><span class="co"># Time points and coordinates</span></span>
<span id="cb2-8" class="hljs-ln-code"><a href="#cb2-8"></a>times <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"bikedata_times.mat"</span>)</span>
<span id="cb2-9" class="hljs-ln-code"><a href="#cb2-9"></a>times <span class="ot">&lt;-</span> times<span class="sc">$</span>time.char</span>
<span id="cb2-10" class="hljs-ln-code"><a href="#cb2-10"></a>times <span class="ot">&lt;-</span> <span class="fu">as.POSIXlt</span>(times)</span>
<span id="cb2-11" class="hljs-ln-code"><a href="#cb2-11"></a></span>
<span id="cb2-12" class="hljs-ln-code"><a href="#cb2-12"></a>coords <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"coords.mat"</span>)</span>
<span id="cb2-13" class="hljs-ln-code"><a href="#cb2-13"></a>coords <span class="ot">&lt;-</span> coords<span class="sc">$</span>coords</span>
<span id="cb2-14" class="hljs-ln-code"><a href="#cb2-14"></a></span>
<span id="cb2-15" class="hljs-ln-code"><a href="#cb2-15"></a><span class="co"># Distance matrix</span></span>
<span id="cb2-16" class="hljs-ln-code"><a href="#cb2-16"></a></span>
<span id="cb2-17" class="hljs-ln-code"><a href="#cb2-17"></a><span class="co"># Average bikes per station</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-2" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb3-1" class="hljs-ln-code"><a href="#cb3-1"></a><span class="fu">library</span>(<span class="st">"R.matlab"</span>)</span>
<span id="cb3-2" class="hljs-ln-code"><a href="#cb3-2"></a></span>
<span id="cb3-3" class="hljs-ln-code"><a href="#cb3-3"></a><span class="co"># Bike data</span></span>
<span id="cb3-4" class="hljs-ln-code"><a href="#cb3-4"></a>bikes <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"bikedata.mat"</span>)</span>
<span id="cb3-5" class="hljs-ln-code"><a href="#cb3-5"></a>bikes <span class="ot">&lt;-</span> bikes<span class="sc">$</span>bikes</span>
<span id="cb3-6" class="hljs-ln-code"><a href="#cb3-6"></a></span>
<span id="cb3-7" class="hljs-ln-code"><a href="#cb3-7"></a><span class="co"># Time points and coordinates</span></span>
<span id="cb3-8" class="hljs-ln-code"><a href="#cb3-8"></a>times <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"bikedata_times.mat"</span>)</span>
<span id="cb3-9" class="hljs-ln-code"><a href="#cb3-9"></a>times <span class="ot">&lt;-</span> times<span class="sc">$</span>time.char</span>
<span id="cb3-10" class="hljs-ln-code"><a href="#cb3-10"></a>times <span class="ot">&lt;-</span> <span class="fu">as.POSIXlt</span>(times)</span>
<span id="cb3-11" class="hljs-ln-code"><a href="#cb3-11"></a></span>
<span id="cb3-12" class="hljs-ln-code"><a href="#cb3-12"></a>coords <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"coords.mat"</span>)</span>
<span id="cb3-13" class="hljs-ln-code"><a href="#cb3-13"></a>coords <span class="ot">&lt;-</span> coords<span class="sc">$</span>coords</span>
<span id="cb3-14" class="hljs-ln-code"><a href="#cb3-14"></a></span>
<span id="cb3-15" class="hljs-ln-code"><a href="#cb3-15"></a><span class="co"># Distance matrix</span></span>
<span id="cb3-16" class="hljs-ln-code"><a href="#cb3-16"></a>n         <span class="ot">&lt;-</span> <span class="fu">dim</span>(coords)[<span class="dv">1</span>]</span>
<span id="cb3-17" class="hljs-ln-code"><a href="#cb3-17"></a>aux.x     <span class="ot">&lt;-</span> coords[,<span class="dv">1</span>] <span class="sc">%*%</span> <span class="fu">t</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n)) <span class="sc">-</span> <span class="fu">rep</span>(<span class="dv">1</span>, n) <span class="sc">%*%</span> <span class="fu">t</span>(coords[,<span class="dv">1</span>])</span>
<span id="cb3-18" class="hljs-ln-code"><a href="#cb3-18"></a>aux.y     <span class="ot">&lt;-</span> coords[,<span class="dv">2</span>] <span class="sc">%*%</span> <span class="fu">t</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n)) <span class="sc">-</span> <span class="fu">rep</span>(<span class="dv">1</span>, n) <span class="sc">%*%</span> <span class="fu">t</span>(coords[,<span class="dv">2</span>])</span>
<span id="cb3-19" class="hljs-ln-code"><a href="#cb3-19"></a>dist_mat  <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(aux.x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> aux.y<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb3-20" class="hljs-ln-code"><a href="#cb3-20"></a></span>
<span id="cb3-21" class="hljs-ln-code"><a href="#cb3-21"></a><span class="co"># Average bikes per station</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-3" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb4-1" class="hljs-ln-code"><a href="#cb4-1"></a><span class="fu">library</span>(<span class="st">"R.matlab"</span>)</span>
<span id="cb4-2" class="hljs-ln-code"><a href="#cb4-2"></a></span>
<span id="cb4-3" class="hljs-ln-code"><a href="#cb4-3"></a><span class="co"># Bike data</span></span>
<span id="cb4-4" class="hljs-ln-code"><a href="#cb4-4"></a>bikes <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"bikedata.mat"</span>)</span>
<span id="cb4-5" class="hljs-ln-code"><a href="#cb4-5"></a>bikes <span class="ot">&lt;-</span> bikes<span class="sc">$</span>bikes</span>
<span id="cb4-6" class="hljs-ln-code"><a href="#cb4-6"></a></span>
<span id="cb4-7" class="hljs-ln-code"><a href="#cb4-7"></a><span class="co"># Time points and coordinates</span></span>
<span id="cb4-8" class="hljs-ln-code"><a href="#cb4-8"></a>times <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"bikedata_times.mat"</span>)</span>
<span id="cb4-9" class="hljs-ln-code"><a href="#cb4-9"></a>times <span class="ot">&lt;-</span> times<span class="sc">$</span>time.char</span>
<span id="cb4-10" class="hljs-ln-code"><a href="#cb4-10"></a>times <span class="ot">&lt;-</span> <span class="fu">as.POSIXlt</span>(times)</span>
<span id="cb4-11" class="hljs-ln-code"><a href="#cb4-11"></a></span>
<span id="cb4-12" class="hljs-ln-code"><a href="#cb4-12"></a>coords <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">"coords.mat"</span>)</span>
<span id="cb4-13" class="hljs-ln-code"><a href="#cb4-13"></a>coords <span class="ot">&lt;-</span> coords<span class="sc">$</span>coords</span>
<span id="cb4-14" class="hljs-ln-code"><a href="#cb4-14"></a></span>
<span id="cb4-15" class="hljs-ln-code"><a href="#cb4-15"></a><span class="co"># Distance matrix</span></span>
<span id="cb4-16" class="hljs-ln-code"><a href="#cb4-16"></a>n         <span class="ot">&lt;-</span> <span class="fu">dim</span>(coords)[<span class="dv">1</span>]</span>
<span id="cb4-17" class="hljs-ln-code"><a href="#cb4-17"></a>aux.x     <span class="ot">&lt;-</span> coords[,<span class="dv">1</span>] <span class="sc">%*%</span> <span class="fu">t</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n)) <span class="sc">-</span> <span class="fu">rep</span>(<span class="dv">1</span>, n) <span class="sc">%*%</span> <span class="fu">t</span>(coords[,<span class="dv">1</span>])</span>
<span id="cb4-18" class="hljs-ln-code"><a href="#cb4-18"></a>aux.y     <span class="ot">&lt;-</span> coords[,<span class="dv">2</span>] <span class="sc">%*%</span> <span class="fu">t</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n)) <span class="sc">-</span> <span class="fu">rep</span>(<span class="dv">1</span>, n) <span class="sc">%*%</span> <span class="fu">t</span>(coords[,<span class="dv">2</span>])</span>
<span id="cb4-19" class="hljs-ln-code"><a href="#cb4-19"></a>dist_mat  <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(aux.x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> aux.y<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb4-20" class="hljs-ln-code"><a href="#cb4-20"></a></span>
<span id="cb4-21" class="hljs-ln-code"><a href="#cb4-21"></a><span class="co"># Average bikes across all stations</span></span>
<span id="cb4-22" class="hljs-ln-code"><a href="#cb4-22"></a>avg_bikes <span class="ot">&lt;-</span> <span class="fu">apply</span>(bikes, <span class="dv">1</span>, mean, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">

</div>
</section>
<section id="section-4" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># time lag k = 1, ...</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>k <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="fu">plot</span>(avg_bikes[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)], avg_bikes[<span class="sc">-</span><span class="fu">c</span>((<span class="fu">length</span>(avg_bikes)<span class="sc">-</span>k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(avg_bikes))], </span>
<span id="cb5-5"><a href="#cb5-5"></a>       <span class="at">col =</span> color_vector[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)],</span>
<span id="cb5-6"><a href="#cb5-6"></a>       <span class="at">xlab =</span> <span class="st">"Average number of bikes per station"</span>, </span>
<span id="cb5-7"><a href="#cb5-7"></a>       <span class="at">ylab =</span> <span class="st">"Average number of bikes per station 5 minutes ago"</span>,</span>
<span id="cb5-8"><a href="#cb5-8"></a>       <span class="at">axes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb5-9"><a href="#cb5-9"></a>  <span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span>
<span id="cb5-10"><a href="#cb5-10"></a>  <span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-2-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section id="section-5" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb6" data-code-line-numbers="2,7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># time lag k = 1, ...</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>k <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="fu">plot</span>(avg_bikes[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)], avg_bikes[<span class="sc">-</span><span class="fu">c</span>((<span class="fu">length</span>(avg_bikes)<span class="sc">-</span>k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(avg_bikes))], </span>
<span id="cb6-5"><a href="#cb6-5"></a>       <span class="at">col =</span> color_vector[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)],</span>
<span id="cb6-6"><a href="#cb6-6"></a>       <span class="at">xlab =</span> <span class="st">"Average number of bikes per station"</span>, </span>
<span id="cb6-7"><a href="#cb6-7"></a>       <span class="at">ylab =</span> <span class="st">"Average number of bikes per station 10 minutes ago"</span>,</span>
<span id="cb6-8"><a href="#cb6-8"></a>       <span class="at">axes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb6-9"><a href="#cb6-9"></a>  <span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span>
<span id="cb6-10"><a href="#cb6-10"></a>  <span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-3-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section id="section-6" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7" data-code-line-numbers="2,7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># time lag k = 1, ...</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>k <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb7-3"><a href="#cb7-3"></a></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="fu">plot</span>(avg_bikes[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)], avg_bikes[<span class="sc">-</span><span class="fu">c</span>((<span class="fu">length</span>(avg_bikes)<span class="sc">-</span>k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(avg_bikes))], </span>
<span id="cb7-5"><a href="#cb7-5"></a>       <span class="at">col =</span> color_vector[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)],</span>
<span id="cb7-6"><a href="#cb7-6"></a>       <span class="at">xlab =</span> <span class="st">"Average number of bikes per station"</span>, </span>
<span id="cb7-7"><a href="#cb7-7"></a>       <span class="at">ylab =</span> <span class="st">"Average number of bikes per station 15 minutes ago"</span>,</span>
<span id="cb7-8"><a href="#cb7-8"></a>       <span class="at">axes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span>
<span id="cb7-10"><a href="#cb7-10"></a>  <span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-4-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section id="section-7" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8" data-code-line-numbers="2,7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># time lag k = 1, ...</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>k <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="fu">plot</span>(avg_bikes[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)], avg_bikes[<span class="sc">-</span><span class="fu">c</span>((<span class="fu">length</span>(avg_bikes)<span class="sc">-</span>k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(avg_bikes))], </span>
<span id="cb8-5"><a href="#cb8-5"></a>       <span class="at">col =</span> color_vector[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)],</span>
<span id="cb8-6"><a href="#cb8-6"></a>       <span class="at">xlab =</span> <span class="st">"Average number of bikes per station"</span>, </span>
<span id="cb8-7"><a href="#cb8-7"></a>       <span class="at">ylab =</span> <span class="st">"Average number of bikes per station 20 minutes ago"</span>,</span>
<span id="cb8-8"><a href="#cb8-8"></a>       <span class="at">axes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb8-9"><a href="#cb8-9"></a>  <span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span>
<span id="cb8-10"><a href="#cb8-10"></a>  <span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-5-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section id="section-8" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9" data-code-line-numbers="2,7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># time lag k = 1, ...</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>k <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="fu">plot</span>(avg_bikes[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)], avg_bikes[<span class="sc">-</span><span class="fu">c</span>((<span class="fu">length</span>(avg_bikes)<span class="sc">-</span>k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(avg_bikes))], </span>
<span id="cb9-5"><a href="#cb9-5"></a>       <span class="at">col =</span> color_vector[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)],</span>
<span id="cb9-6"><a href="#cb9-6"></a>       <span class="at">xlab =</span> <span class="st">"Average number of bikes per station"</span>, </span>
<span id="cb9-7"><a href="#cb9-7"></a>       <span class="at">ylab =</span> <span class="st">"Average number of bikes per station one hour ago"</span>,</span>
<span id="cb9-8"><a href="#cb9-8"></a>       <span class="at">axes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb9-9"><a href="#cb9-9"></a>  <span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span>
<span id="cb9-10"><a href="#cb9-10"></a>  <span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-6-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section id="section-9" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10" data-code-line-numbers="2,7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># time lag k = 1, ...</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>k <span class="ot">&lt;-</span> <span class="dv">24</span></span>
<span id="cb10-3"><a href="#cb10-3"></a></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="fu">plot</span>(avg_bikes[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)], avg_bikes[<span class="sc">-</span><span class="fu">c</span>((<span class="fu">length</span>(avg_bikes)<span class="sc">-</span>k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(avg_bikes))], </span>
<span id="cb10-5"><a href="#cb10-5"></a>       <span class="at">col =</span> color_vector[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>k)],</span>
<span id="cb10-6"><a href="#cb10-6"></a>       <span class="at">xlab =</span> <span class="st">"Average number of bikes per station"</span>, </span>
<span id="cb10-7"><a href="#cb10-7"></a>       <span class="at">ylab =</span> <span class="st">"Average number of bikes per station two hours ago"</span>,</span>
<span id="cb10-8"><a href="#cb10-8"></a>       <span class="at">axes =</span> <span class="cn">FALSE</span>)</span>
<span id="cb10-9"><a href="#cb10-9"></a>  <span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span>
<span id="cb10-10"><a href="#cb10-10"></a>  <span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">by =</span> <span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-7-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section class="slide level2">

<ul>
<li>If two observations are close in time, they are likely to be similar</li>
<li><strong>Temporal Dependence</strong> in a statistical sense</li>
</ul>
<div class="fragment">
<ul>
<li>There is typically a causal relation across time, i.e., if the number of bikes in a dock <span class="math inline">\(\textbf{s}\)</span> is high at 10:00, then it stays high at 10:05 <span class="math inline">\(\rightsquigarrow\)</span> <span class="math inline">\(Y_t(\textbf{s})\)</span> is influenced by <span class="math inline">\(Y_{t-1}(\textbf{s})\)</span></li>
</ul>
</div>
</section>
<section class="slide level2">

<div class="cell">

</div>
<div class="cell" data-layout-align="center">
<details>
<summary>Expand for full code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">library</span>(<span class="st">"ggmap"</span>, <span class="st">"ggplot2"</span>)</span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a>map <span class="ot">&lt;-</span> <span class="fu">get_map</span>(<span class="at">location =</span> <span class="fu">apply</span>(coords, <span class="dv">2</span>, mean), <span class="at">zoom =</span> <span class="dv">12</span>)</span>
<span id="cb11-4"><a href="#cb11-4"></a>sites <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">longitude =</span> coords[, <span class="dv">1</span>], <span class="at">latitude =</span> coords[, <span class="dv">2</span>])</span>
<span id="cb11-5"><a href="#cb11-5"></a></span>
<span id="cb11-6"><a href="#cb11-6"></a><span class="fu">ggmap</span>(map) <span class="sc">+</span></span>
<span id="cb11-7"><a href="#cb11-7"></a> <span class="fu">geom_point</span>(<span class="at">data =</span> sites, <span class="fu">aes</span>(<span class="at">x =</span> longitude, <span class="at">y =</span> latitude)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-9-1.png" width="864"></p>
</figure>
</div>
</div>
<details>
<summary>Expand for full code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>bikes_space <span class="ot">&lt;-</span> bikes[<span class="fu">which</span>(<span class="fu">months</span>(times) <span class="sc">==</span> <span class="st">"July"</span>), ]</span>
<span id="cb12-2"><a href="#cb12-2"></a></span>
<span id="cb12-3"><a href="#cb12-3"></a>k       <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb12-4"><a href="#cb12-4"></a>t       <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a>knnW    <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="cf">function</span>(i) <span class="fu">ifelse</span>(dist_mat[i,] <span class="sc">&lt;</span> <span class="fu">sort</span>(dist_mat[i,])[k<span class="sc">+</span><span class="dv">2</span>] <span class="sc">&amp;</span> dist_mat[i,] <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span><span class="sc">/</span>k, <span class="dv">0</span>))) <span class="co"># k+2, because of the diagonal zero entry and the strict inequality</span></span>
<span id="cb12-7"><a href="#cb12-7"></a><span class="fu">plot</span>(bikes_space[t,], </span>
<span id="cb12-8"><a href="#cb12-8"></a>     knnW <span class="sc">%*%</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(bikes_space[t,]), <span class="fu">mean</span>(bikes_space[t,], <span class="at">na.rm =</span> <span class="cn">TRUE</span>), bikes_space[t,]), </span>
<span id="cb12-9"><a href="#cb12-9"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">60</span>), </span>
<span id="cb12-10"><a href="#cb12-10"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">60</span>),</span>
<span id="cb12-11"><a href="#cb12-11"></a>     <span class="at">ylab =</span> <span class="st">"Average bike count of k-nearest neighbours"</span>,</span>
<span id="cb12-12"><a href="#cb12-12"></a>     <span class="at">xlab =</span> <span class="st">"Average bike count midnight"</span>,</span>
<span id="cb12-13"><a href="#cb12-13"></a>     <span class="at">col =</span> color_vector[t])</span>
<span id="cb12-14"><a href="#cb12-14"></a></span>
<span id="cb12-15"><a href="#cb12-15"></a>x <span class="ot">&lt;-</span> knnW <span class="sc">%*%</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(bikes_space[t,]), <span class="fu">mean</span>(bikes_space[t,], <span class="at">na.rm =</span> <span class="cn">TRUE</span>), bikes_space[t,])</span>
<span id="cb12-16"><a href="#cb12-16"></a>ab <span class="ot">&lt;-</span> <span class="fu">lm</span>(bikes_space[t,] <span class="sc">~</span> x)<span class="sc">$</span>coeff</span>
<span id="cb12-17"><a href="#cb12-17"></a><span class="fu">text</span>(<span class="dv">50</span>, <span class="dv">50</span>, ab[<span class="dv">2</span>])</span>
<span id="cb12-18"><a href="#cb12-18"></a><span class="fu">abline</span>(<span class="at">a =</span> ab[<span class="dv">1</span>], <span class="at">b =</span> ab[<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-9-2.png" width="864"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="section-10" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb13-1" class="hljs-ln-code"><a href="#cb13-1"></a><span class="fu">library</span>(<span class="st">"spdep"</span>)</span>
<span id="cb13-2" class="hljs-ln-code"><a href="#cb13-2"></a>h <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># index time point across the day</span></span>
<span id="cb13-3" class="hljs-ln-code"><a href="#cb13-3"></a></span>
<span id="cb13-4" class="hljs-ln-code"><a href="#cb13-4"></a>M.I    <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb13-5" class="hljs-ln-code"><a href="#cb13-5"></a>M.Ip   <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb13-6" class="hljs-ln-code"><a href="#cb13-6"></a></span>
<span id="cb13-7" class="hljs-ln-code"><a href="#cb13-7"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb13-8" class="hljs-ln-code"><a href="#cb13-8"></a>    knnW    <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="cf">function</span>(i) <span class="fu">ifelse</span>(dist_mat[i,] <span class="sc">&lt;</span> <span class="fu">sort</span>(dist_mat[i,])[k<span class="sc">+</span><span class="dv">2</span>] <span class="sc">&amp;</span> dist_mat[i,] <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span><span class="sc">/</span>k, <span class="dv">0</span>)))</span>
<span id="cb13-9" class="hljs-ln-code"><a href="#cb13-9"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-11" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb14-1" class="hljs-ln-code"><a href="#cb14-1"></a><span class="fu">library</span>(<span class="st">"spdep"</span>)</span>
<span id="cb14-2" class="hljs-ln-code"><a href="#cb14-2"></a>h <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># index time point across the day</span></span>
<span id="cb14-3" class="hljs-ln-code"><a href="#cb14-3"></a></span>
<span id="cb14-4" class="hljs-ln-code"><a href="#cb14-4"></a>M.I    <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb14-5" class="hljs-ln-code"><a href="#cb14-5"></a>M.Ip   <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb14-6" class="hljs-ln-code"><a href="#cb14-6"></a></span>
<span id="cb14-7" class="hljs-ln-code"><a href="#cb14-7"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb14-8" class="hljs-ln-code"><a href="#cb14-8"></a>    knnW    <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="cf">function</span>(i) <span class="fu">ifelse</span>(dist_mat[i,] <span class="sc">&lt;</span> <span class="fu">sort</span>(dist_mat[i,])[k<span class="sc">+</span><span class="dv">2</span>] <span class="sc">&amp;</span> dist_mat[i,] <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span><span class="sc">/</span>k, <span class="dv">0</span>)))</span>
<span id="cb14-9" class="hljs-ln-code"><a href="#cb14-9"></a>    out     <span class="ot">&lt;-</span> <span class="fu">moran.test</span>(<span class="fu">apply</span>(bikes_space[<span class="fu">which</span>(times<span class="sc">$</span>hour <span class="sc">==</span> h<span class="dv">-1</span>),], <span class="dv">2</span>, mean, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), <span class="fu">mat2listw</span>(knnW))</span>
<span id="cb14-10" class="hljs-ln-code"><a href="#cb14-10"></a>    M.I[k]  <span class="ot">&lt;-</span> out<span class="sc">$</span>estimate[<span class="dv">1</span>]</span>
<span id="cb14-11" class="hljs-ln-code"><a href="#cb14-11"></a>    M.Ip[k] <span class="ot">&lt;-</span> out<span class="sc">$</span>p.value</span>
<span id="cb14-12" class="hljs-ln-code"><a href="#cb14-12"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-12" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell">

</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a>h <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># index time point across the day</span></span>
<span id="cb15-2"><a href="#cb15-2"></a></span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>, M.I, </span>
<span id="cb15-4"><a href="#cb15-4"></a>      <span class="at">col =</span> colors[h],</span>
<span id="cb15-5"><a href="#cb15-5"></a>      <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Spatial Correlation (Moran's I) at "</span>, h<span class="dv">-1</span>, <span class="st">":00"</span>, <span class="at">sep =</span> <span class="st">""</span>), </span>
<span id="cb15-6"><a href="#cb15-6"></a>      <span class="at">pch =</span> <span class="fu">ifelse</span>(M.Ip <span class="sc">&lt;</span> <span class="fl">0.05</span>, <span class="dv">20</span>, <span class="dv">1</span>), </span>
<span id="cb15-7"><a href="#cb15-7"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.8</span>), </span>
<span id="cb15-8"><a href="#cb15-8"></a>      <span class="at">axes =</span> <span class="cn">FALSE</span>,</span>
<span id="cb15-9"><a href="#cb15-9"></a>      <span class="at">xlab =</span> <span class="st">"Spatial lag order (k-nearest neighbours)"</span>,</span>
<span id="cb15-10"><a href="#cb15-10"></a>      <span class="at">ylab =</span> <span class="st">"Spatial correlation (Moran's I)"</span>)</span>
<span id="cb15-11"><a href="#cb15-11"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">20</span>, <span class="dv">120</span>, <span class="at">by =</span> <span class="dv">10</span>))</span>
<span id="cb15-12"><a href="#cb15-12"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-11-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section id="section-13" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16" data-code-line-numbers="1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>h <span class="ot">&lt;-</span> <span class="dv">8</span> <span class="co"># index time point across the day</span></span>
<span id="cb16-2"><a href="#cb16-2"></a></span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>, M.I, </span>
<span id="cb16-4"><a href="#cb16-4"></a>      <span class="at">col =</span> colors[h],</span>
<span id="cb16-5"><a href="#cb16-5"></a>      <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Spatial Correlation (Moran's I) at "</span>, h<span class="dv">-1</span>, <span class="st">":00"</span>, <span class="at">sep =</span> <span class="st">""</span>), </span>
<span id="cb16-6"><a href="#cb16-6"></a>      <span class="at">pch =</span> <span class="fu">ifelse</span>(M.Ip <span class="sc">&lt;</span> <span class="fl">0.05</span>, <span class="dv">20</span>, <span class="dv">1</span>), </span>
<span id="cb16-7"><a href="#cb16-7"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.8</span>), </span>
<span id="cb16-8"><a href="#cb16-8"></a>      <span class="at">axes =</span> <span class="cn">FALSE</span>,</span>
<span id="cb16-9"><a href="#cb16-9"></a>      <span class="at">xlab =</span> <span class="st">"Spatial lag order (k-nearest neighbours)"</span>,</span>
<span id="cb16-10"><a href="#cb16-10"></a>      <span class="at">ylab =</span> <span class="st">"Spatial correlation (Moran's I)"</span>)</span>
<span id="cb16-11"><a href="#cb16-11"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">20</span>, <span class="dv">120</span>, <span class="at">by =</span> <span class="dv">10</span>))</span>
<span id="cb16-12"><a href="#cb16-12"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-13-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section id="section-14" class="slide level2 unnumbered" data-transition="none">
<h2></h2>
<div class="cell" data-layout-align="center">

</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17" data-code-line-numbers="1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a>h <span class="ot">&lt;-</span> <span class="dv">13</span> <span class="co"># index time point across the day</span></span>
<span id="cb17-2"><a href="#cb17-2"></a></span>
<span id="cb17-3"><a href="#cb17-3"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>, M.I, </span>
<span id="cb17-4"><a href="#cb17-4"></a>      <span class="at">col =</span> colors[h],</span>
<span id="cb17-5"><a href="#cb17-5"></a>      <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Spatial Correlation (Moran's I) at "</span>, h<span class="dv">-1</span>, <span class="st">":00"</span>, <span class="at">sep =</span> <span class="st">""</span>), </span>
<span id="cb17-6"><a href="#cb17-6"></a>      <span class="at">pch =</span> <span class="fu">ifelse</span>(M.Ip <span class="sc">&lt;</span> <span class="fl">0.05</span>, <span class="dv">20</span>, <span class="dv">1</span>), </span>
<span id="cb17-7"><a href="#cb17-7"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.8</span>), </span>
<span id="cb17-8"><a href="#cb17-8"></a>      <span class="at">axes =</span> <span class="cn">FALSE</span>,</span>
<span id="cb17-9"><a href="#cb17-9"></a>      <span class="at">xlab =</span> <span class="st">"Spatial lag order (k-nearest neighbours)"</span>,</span>
<span id="cb17-10"><a href="#cb17-10"></a>      <span class="at">ylab =</span> <span class="st">"Spatial correlation (Moran's I)"</span>)</span>
<span id="cb17-11"><a href="#cb17-11"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">20</span>, <span class="dv">120</span>, <span class="at">by =</span> <span class="dv">10</span>))</span>
<span id="cb17-12"><a href="#cb17-12"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-15-1.png" width="864" class="r-stretch quarto-figure-center"></section>
<section class="slide level2">

<ul>
<li>If two observations are located nearby in space, they are likely to be similar</li>
<li><strong>Spatial Dependence</strong> in a statistical sense</li>
</ul>
<div class="fragment">
<ul>
<li>Toblers first law of geography: everything is related to everything else, but near things are more related than distant things. <span class="citation" data-cites="Tobler70">(<a href="#/references" role="doc-biblioref" onclick="">Tobler 1970</a>)</span></li>
<li>or the widely verified fact that patches in close proximity are commonly more alike, as judged by the yield of crops, than those which are further apart. <span class="citation" data-cites="fisher1935design">(<a href="#/references" role="doc-biblioref" onclick="">Fisher 1935</a>)</span></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>In contrast to time, there is no clear causal relation between observations across space (due to the temporal simultaneity) <span class="math inline">\(\rightsquigarrow\)</span> <span class="math inline">\(Y_t(\textbf{s}_1)\)</span> depends on <span class="math inline">\(Y_t(\textbf{s}_2)\)</span> and simultaneously <span class="math inline">\(Y_t(\textbf{s}_2)\)</span> depends on <span class="math inline">\(Y_t(\textbf{s}_1)\)</span></li>
</ul>
</div>
</section>
<section class="slide level2">

<ul>
<li>Most standard statistical models (e.g.&nbsp;linear regression) require independent and identically distributed errors</li>
<li>If temporal, spatial, or spatiotemporal autocorrelation is ignored, the estimated parameters will be inconsistent</li>
</ul>
<div class="fragment">
<ul>
<li>Spatiotemporal variables are often cross-correlated due to their spatial nature (Toblers first law of geography)
<ul>
<li>For instance, air pollution is strongly influenced by the height of the planetary boundary layer (PBL), which also influences most weather covariates, such as wind speed, solar intensity, etc.</li>
<li>Variable selection in spatiotemporal models</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>High-dimensional problem, i.e., there are <span class="math inline">\(n^2-n\)</span> potential interactions between <span class="math inline">\(n\)</span> locations</li>
</ul>
</div>
</section>
<section class="slide level2">

<p>There are different ways to account for such spatial dependence in the observed process:</p>
<ul>
<li><strong>Geographically weighted regression</strong>: Relation between the dependent and independent variables may vary across space</li>
</ul>
<div class="fragment">
<ul>
<li><strong>Geostatistics</strong>: Covariance between <span class="math inline">\(Y_t(\boldsymbol{s})\)</span> and <span class="math inline">\(Y_t(\boldsymbol{s}')\)</span> is supposed to follow a covariance function <span class="math inline">\(C(\boldsymbol{s} - \boldsymbol{s}')\)</span> or <span class="math inline">\(C(||\boldsymbol{s} - \boldsymbol{s}'||)\)</span> in the isotropic case (e.g.&nbsp;a Matrn covariance function)
<ul>
<li>Choice of <span class="math inline">\(C\)</span> and the distance function</li>
<li>Interpretation of the spatial interaction effects
<ul>
<li>Big-<span class="math inline">\(n\)</span> problem</li>
</ul></li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Spatial autoregression</strong> (also often known as spatial econometrics models): Dependent variable at a specific location is influences by its own neighbours defined by a spatial weights matrix <span class="math inline">\(\mathbf{W}\)</span>
<ul>
<li>Choice of <span class="math inline">\(\mathbf{W}\)</span> (which often also depends on distance measures)
<ul>
<li>Complicated covariance structure, conditional independence</li>
<li>Big-<span class="math inline">\(n\)</span> problem</li>
</ul></li>
</ul></li>
</ul>
</div>
</section></section>
<section>
<section id="spatiotemporal-processes" class="title-slide slide level1 center" data-number="2">
<h1><span class="header-section-number">2</span> Spatiotemporal Processes</h1>

</section>
<section class="slide level2">

<p>Stochastic processes are (random) observations drawn from data-generating process, which have a certain order in a predefined space, e.g.</p>
<div class="fragment">
<ul>
<li>time series (daily returns of a financial asset, acceleration of a car (each second, millisecond, etc.), )</li>
<li>spatial processes (todays (maximum) wind speed at different locations, particulate matter distribution in the atmosphere, )</li>
<li>spatiotemporal processes (concentration of air pollutants at several locations observed over time, satellite measurements of <span class="math inline">\(CO_2\)</span>, )</li>
</ul>
</div>
<div class="fragment">
<p>Classical statistical methods, like ordinary-least squares estimators of linear/nonlinear regression models, typically require independent data. Meaning, observations should not depend on other observations. But, </p>
</div>
</section>
<section class="slide level2">

<p>Let <span class="math inline">\(\boldsymbol{s} \in \mathbb{R}^d\)</span> be a location in the <span class="math inline">\(d\)</span>-dimensional space. This covers</p>
<ul>
<li>temporal domains with <span class="math inline">\(d = 1\)</span></li>
<li>spatial domains with <span class="math inline">\(d &gt; 1\)</span></li>
<li>spatiotemporal domains with <span class="math inline">\(d &gt; 2\)</span>, where 1 dimension represents time</li>
</ul>
<p>However, we typically observe data only in a finite space <span class="math inline">\(D \subset \mathbb{R}^d\)</span>. Here, we consider that <span class="math inline">\(D\)</span> is fixed (non random).</p>
<p>Further, let <span class="math inline">\(Z(\boldsymbol{s})\)</span> be (univariate) random variable (datum) at location <span class="math inline">\(\boldsymbol{s}\)</span>, i.e., <span class="math inline">\(Z(\boldsymbol{s}) \in \boldsymbol{R}\)</span>. Note that one might also consider multivariate variables <span class="math inline">\(\boldsymbol{Z} = (Z_1, \ldots, Z_p)'\)</span>. Now, a spatial stochastic process is defined as <span class="math display">\[ \{Z(\boldsymbol{s}) : \boldsymbol{s} \in D \} \, .\]</span></p>
<p>Moreover, denote the observed process by <span class="math display">\[ \{z(\boldsymbol{s}) : \boldsymbol{s} \in D \} \, . \]</span></p>
</section>
<section id="geostatistical-models" class="slide level2" data-number="2.1">
<h2><span class="header-section-number">2.1</span> Geostatistical Models</h2>
<p>Observations are likely to be influenced by observations in the close neighborhood. That means we typically observe similar patterns for observations, which are close in space. This influence usually weakens with increasing distance between the observations.</p>
<div class="callout callout-tip callout-captioned callout-style-simple">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Spatial stochastic process</strong></p>
</div>
<div class="callout-content">
<p>The random process <span class="math inline">\(\{Z(\boldsymbol{s})\}\)</span> can be defined by a distribution <span class="math inline">\(F_{Z(\boldsymbol{s}_1), \ldots, Z(\boldsymbol{s}_n)}\)</span>.</p>
<p><span class="math display">\[F_{Z(\boldsymbol{s}_1), \ldots, Z(\boldsymbol{s}_n)}(z_1, \ldots, z_n) = P(Z(\boldsymbol{s}_1) \leq z_1, \ldots, Z(\boldsymbol{s}_n) \leq z_n)\]</span> <span class="math inline">\(P\)</span> is called probability measure.</p>
</div>
</div>
</div>
<p>There are certain measures describing characteristics/properties of a distribution function <span class="math inline">\(F\)</span>, like the expectation of <span class="math inline">\(F\)</span>, (co-)variance of <span class="math inline">\(F\)</span>, etc. These measures also define the spatial dependence.</p>
<div class="fragment">
<div class="callout callout-tip callout-captioned callout-style-simple">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>First-order stationarity</strong></p>
</div>
<div class="callout-content">
<p>If the expectation <span class="math display">\[E(Z(\boldsymbol{s}_i)) = \mu \qquad \text{for all $i$},\]</span> the process is called first-order stationary. That is, the mean does not depend on the location.</p>
</div>
</div>
</div>
</div>
<div class="fragment">
<div class="callout callout-note callout-captioned callout-style-simple">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Spatial dependence</strong></p>
</div>
<div class="callout-content">
<p>Spatial dependence is characterized by <span class="math display">\[Cov(Z(\boldsymbol{s}_i), Z(\boldsymbol{s}_j))\]</span> for <span class="math inline">\(i \neq j\)</span>. We often need to assume additionally that <span class="math display">\[Cov(Z(\boldsymbol{s}_i), Z(\boldsymbol{s}_j)) = C(\boldsymbol{s}_i - \boldsymbol{s}_j)\, ,\]</span> that is, the covariance is a function of the difference between <span class="math inline">\(\boldsymbol{s}_i\)</span> and <span class="math inline">\(\boldsymbol{s}_j\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-tip callout-captioned callout-style-simple">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Stationarity</strong></p>
</div>
<div class="callout-content">
<p>If these two assumptions are fulfilled, the process is called <strong>weakly stationary</strong>.</p>
</div>
</div>
</div>
<p>This means that the distribution of the random process is the same in all locations and the dependence between the random variables does also not depend on the location, but only on the difference between two locations. In the special case that the dependence is the same into all directions (depending only on the distance between two locations, but not the orientation towards each other), the process is isotropic.</p>
</div>
<div class="fragment">
<div class="callout callout-tip callout-captioned callout-style-simple">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Isotropy</strong></p>
</div>
<div class="callout-content">
<p>If there is a norm <span class="math inline">\(|| \cdot ||\)</span>, such that <span class="math inline">\(C(\cdot)\)</span> is only a function of <span class="math inline">\(||\boldsymbol{s}_i - \boldsymbol{s}_j||\)</span>, the process (or rather <span class="math inline">\(C(\cdot)\)</span>) is called <strong>isotropic</strong>.</p>
</div>
</div>
</div>
<p>One might also assume that <span class="math inline">\(F_{Z(\boldsymbol{s})}(z) = P(Z(\boldsymbol{s}) &lt; z)\)</span> for all <span class="math inline">\(i\)</span>, then the distribution of <span class="math inline">\(\{Z(\boldsymbol{s})\}\)</span> is called to be invariant.</p>
<div class="callout callout-tip callout-captioned callout-style-simple">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Homogeneity</strong></p>
</div>
<div class="callout-content">
<p>If the process is stationary and concurrently isotropic, it is called a <strong>homogeneous</strong> process.</p>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2">

<h3 data-number="2.1.1" id="gaussian-processes"><span class="header-section-number">2.1.1</span> Gaussian Processes</h3>
<p>The random process <span class="math inline">\(\{Z(\boldsymbol{s})\}\)</span> is called Gaussian process if it follows a multivariate normal distribution, i.e., <span class="math inline">\(F_{Z(\boldsymbol{s}_1), \ldots, Z(\boldsymbol{s}_n)} = \Phi_n\)</span> with a mean vector <span class="math inline">\(\boldsymbol{\mu}\)</span> and a covariance matrix <span class="math inline">\(\mathbf{\Sigma}\)</span>.</p>
<div class="fragment">
<p>The elements of <span class="math inline">\(\mathbf{\Sigma}\)</span> typically follow a covariance function <span class="math inline">\(C\)</span>, e.g.</p>
<ul>
<li>White Gaussian noise: <span class="math inline">\(C(\boldsymbol{s} - \boldsymbol{s}') = \sigma^2 \boldsymbol{1}_{\boldsymbol{s} - \boldsymbol{s}' = \boldsymbol{0}}\)</span></li>
<li>Exponential: <span class="math inline">\(C(\boldsymbol{s} - \boldsymbol{s}') = \sigma^2 exp\left(\frac{-|| \boldsymbol{s} - \boldsymbol{s}' ||}{\vartheta}\right)\)</span> (Ornstein-Uhlenbeck if <span class="math inline">\(d = 1\)</span>)</li>
<li>Squared exponential: <span class="math inline">\(C(\boldsymbol{s} - \boldsymbol{s}') = \sigma^2 exp\left(\frac{-|| \boldsymbol{s} - \boldsymbol{s}' ||^2}{2\vartheta^2}\right)\)</span></li>
<li>Matrn: <span class="math inline">\(C(\boldsymbol{s} - \boldsymbol{s}') = \frac{\sigma^2 2^{1-\nu}}{\Gamma(\nu)} \left(\frac{\sqrt{\nu} || \boldsymbol{s} - \boldsymbol{s}' ||}{\vartheta}\right)^{\nu} K_\nu\left(\frac{\sqrt{\nu} || \boldsymbol{s} - \boldsymbol{s}' ||}{\vartheta}\right)\)</span> (<span class="math inline">\(K_\nu\)</span> is the modified Bessel function of order <span class="math inline">\(\nu\)</span>), for <span class="math inline">\(\nu = 1/2\)</span> we get an exponential covariance function</li>
</ul>
</div>
<div class="fragment">
<p>The distance between two points is given by <span class="math inline">\(|| \boldsymbol{s} - \boldsymbol{s}' ||\)</span>, where <span class="math inline">\(|| \cdot ||\)</span> represents a suitable vector norm. The parameter <span class="math inline">\(\vartheta\)</span> is a scaling parameter, which controls the <em>correlation length</em>. Moreover, <span class="math inline">\(\sigma^2\)</span> is the so-called nugget effect (i.e., error variance).</p>
</div>
</section>
<section class="slide level2">

<h3 data-number="2.1.2" id="mixed-effects-models"><span class="header-section-number">2.1.2</span> Mixed-Effects Models</h3>
<p>Consider a geo-referenced univariate process across space and time <span class="math inline">\(\{Y_t(\boldsymbol{s}) \in \mathbb{R}^p: \boldsymbol{s} \in D_{\boldsymbol{s}}, t \in D_t \}\)</span>. Note that <span class="math inline">\(t\)</span> could also be considered as one dimension of <span class="math inline">\(\boldsymbol{s}\)</span>, but it is convenient to have two separate indices for space and time. Moreover, <span class="math inline">\(t\)</span> is often represented as an index.</p>
<div class="fragment">
<p>A mixed-effects spatiotemporal model is specified as <span class="math display">\[\begin{equation}
    Y_t(\boldsymbol{s}) = \mu_t(\boldsymbol{s}) + \omega_t(\boldsymbol{s}) + \varepsilon_t(\boldsymbol{s}) ,
\end{equation}\]</span> where <span class="math inline">\(\mu_t(\boldsymbol{s})\)</span> is the fixed-effects model, <span class="math inline">\(\omega_t(\boldsymbol{s})\)</span> is the random-effects model, and <span class="math inline">\(\varepsilon_t(\boldsymbol{s})\)</span> is the modelling error.</p>
</div>
<div class="fragment">
<ul>
<li>Fixed-effects model: mean behaviour and influence of exogenous variables, large-scale variation
<ul>
<li>Linear regression model <span class="math inline">\(\mu_t(\boldsymbol{s}) = \mathbf{X}_t(\boldsymbol{s})\boldsymbol{\beta}\)</span>,</li>
<li>Non-linear regression models such as generalised additive models <span class="math inline">\(g(\mu_t(\boldsymbol{s})) = \beta_0 + \sum_{k = 1}^{K} f_k(X^{(k)}_t(\boldsymbol{s}))\)</span>,</li>
<li>Random forest <span class="math inline">\(\mu_t(\boldsymbol{s}) = \sum_{i = 1}^{n_{\text{tree}}} \widehat{E(Y^*_t({\boldsymbol{s}}) | \{\mathbf{X}_t(\boldsymbol{s})\})}\)</span> where <span class="math inline">\(\widehat{E(Y^*_t({\boldsymbol{s}}) | \{\mathbf{X}_t(\boldsymbol{s})\})}\)</span> is the predicted mean of the <span class="math inline">\(i\)</span>-th decision tree of the bootstrap sample <span class="math inline">\(Y^*_t({\boldsymbol{s}})\)</span> (sampled with replacement),</li>
<li>Spatial random forest <span class="citation" data-cites="saha2021random">(<a href="#/references" role="doc-biblioref" onclick="">Saha, Basu, and Datta 2021</a>)</span>,</li>
<li>and many others</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Random-effects model: spatial, temporal and spatiotemporal dependence, small-scale variation
<ul>
<li>Gaussian process <span class="math inline">\(\{\omega_t(\boldsymbol{s}) : \boldsymbol{s} \in D_{\boldsymbol{s}}, t \in D_t \} \quad \sim \quad N_p(0, C_\theta(\boldsymbol{s} - \boldsymbol{s}', t - t'))\)</span> with separable/non-separable, stationary/non-stationary, isotropic/anisotropic covariance functions <span class="math inline">\(C_\theta\)</span>, see also <span class="citation" data-cites="Cressie11">Cressie and Wikle (<a href="#/references" role="doc-biblioref" onclick="">2011</a>)</span></li>
<li>other random processes</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Error term: unstructured effects, variation due to ommitted variables
<ul>
<li>typically assumed to be an independent and identically distributed zero-mean process with constant variance (homoscedasticity)</li>
</ul></li>
</ul>
</div>
</section>
<section id="spatial-autoregression-spatial-econometric-models" class="slide level2" data-number="2.2">
<h2><span class="header-section-number">2.2</span> Spatial Autoregression (Spatial Econometric Models)</h2>
<p>Instead of accounting for the spatial/temporal dependence in process with a parametric (or non-parametric) covariance, spatial econometric models explicitly correlate the outcome variables with nearby observations. Thus, they require the definition of the <strong>neighbourhood</strong> structure via the so-called weight matrix <span class="math inline">\(\mathbf{W}\)</span>.</p>
<p>Let <span class="math inline">\(\boldsymbol{Y}_t = (Y_t(\boldsymbol{s}_1), \ldots, Y_t(\boldsymbol{s}_n))'\)</span> be a vector of <span class="math inline">\(Y_t(\boldsymbol{s})\)</span> at all observed sites <span class="math inline">\(\boldsymbol{s}_1, \ldots, \boldsymbol{s}_n\)</span>. Now, each row of <span class="math inline">\(\mathbf{W}\)</span> contains the weights to compute the weighted average of all neighbouring locations (i.e., <span class="math inline">\(\mathbf{W}\boldsymbol{Y}_t\)</span>) like an adjacency matrix in networks.</p>
<div class="fragment">
<p>Possible definitions of <span class="math inline">\(\mathbf{W} = (w_{ij})_{i,j = 1, \ldots, n}\)</span>:</p>
<ul>
<li>Inverse-distance weights: <span class="math inline">\(w_{ij} = ||\boldsymbol{s}_i - \boldsymbol{s}_j ||^{-1}\)</span></li>
<li>Contiguity-based weights: <span class="math inline">\(w_{ij} = 1\)</span> if <span class="math inline">\(\boldsymbol{s}_i\)</span> and <span class="math inline">\(\boldsymbol{s}_j\)</span> share a common border, and <span class="math inline">\(w_{ij} = 0\)</span> otherwise</li>
<li><span class="math inline">\(k\)</span>-nearest neighbours: <span class="math inline">\(w_{ij} = 1\)</span> (or <span class="math inline">\(w_{ij} = 1/k\)</span>) if <span class="math inline">\(\boldsymbol{s}_i\)</span> is closer to <span class="math inline">\(\boldsymbol{s}_j\)</span> than the closest <span class="math inline">\(k+1\)</span> of all locations, and <span class="math inline">\(w_{ij} = 0\)</span> otherwise</li>
<li>and many others</li>
</ul>
</div>
<div class="fragment">
<p>Often the weights are row-standardised, i.e., each row sums to one (however, row-standardisation distorts the distance structure if there are different numbers of neighbours)</p>
</div>
</section>
<section class="slide level2">

<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a><span class="fu">load</span>(<span class="st">"sources/data_berlin.rda"</span>)</span>
<span id="cb18-2"><a href="#cb18-2"></a><span class="fu">library</span>(<span class="st">"maptools"</span>)</span>
<span id="cb18-3"><a href="#cb18-3"></a><span class="fu">library</span>(<span class="st">"spdep"</span>)</span>
<span id="cb18-4"><a href="#cb18-4"></a></span>
<span id="cb18-5"><a href="#cb18-5"></a>B <span class="ot">&lt;-</span> data_berlin<span class="sc">$</span>map </span>
<span id="cb18-6"><a href="#cb18-6"></a>IDs <span class="ot">&lt;-</span> <span class="fu">as.character</span>(<span class="fu">names</span>(B))</span>
<span id="cb18-7"><a href="#cb18-7"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(IDs))</span>
<span id="cb18-8"><a href="#cb18-8"></a></span>
<span id="cb18-9"><a href="#cb18-9"></a><span class="fu">plot</span>(B)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-16-1.png" width="576"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a>IDs4 <span class="ot">&lt;-</span> <span class="fu">substr</span>(<span class="fu">as.character</span>(<span class="fu">names</span>(B)), <span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb19-2"><a href="#cb19-2"></a>n_thin <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(IDs4))</span>
<span id="cb19-3"><a href="#cb19-3"></a></span>
<span id="cb19-4"><a href="#cb19-4"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">gpclibPermitStatus</span>()){</span>
<span id="cb19-5"><a href="#cb19-5"></a>  <span class="fu">gpclibPermit</span>()</span>
<span id="cb19-6"><a href="#cb19-6"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a>B_thin <span class="ot">&lt;-</span> <span class="fu">unionSpatialPolygons</span>(B, IDs4)</span>
<span id="cb21-2"><a href="#cb21-2"></a></span>
<span id="cb21-3"><a href="#cb21-3"></a>coords <span class="ot">&lt;-</span> <span class="fu">array</span>(, <span class="at">dim =</span> <span class="fu">c</span>(<span class="fu">length</span>(B), <span class="dv">2</span>))</span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(B)){</span>
<span id="cb21-5"><a href="#cb21-5"></a>  coords[i,] <span class="ot">&lt;-</span> B<span class="sc">@</span>polygons[[i]]<span class="sc">@</span>labpt</span>
<span id="cb21-6"><a href="#cb21-6"></a>}</span>
<span id="cb21-7"><a href="#cb21-7"></a></span>
<span id="cb21-8"><a href="#cb21-8"></a>cols <span class="ot">&lt;-</span> <span class="fu">colorRampPalette</span>(<span class="fu">c</span>(<span class="st">"white"</span>, <span class="st">"darkblue"</span>))</span>
<span id="cb21-9"><a href="#cb21-9"></a></span>
<span id="cb21-10"><a href="#cb21-10"></a><span class="co"># Inverse-distance matrix</span></span>
<span id="cb21-11"><a href="#cb21-11"></a>W <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">as.matrix</span>(<span class="fu">dist</span>(coords))</span>
<span id="cb21-12"><a href="#cb21-12"></a><span class="fu">diag</span>(W) <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb21-13"><a href="#cb21-13"></a><span class="fu">image</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span><span class="sc">:</span>n, W, <span class="at">col =</span> <span class="fu">cols</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-16-2.png" width="576"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a><span class="co"># Inverse-distance matrix (row-standardised)</span></span>
<span id="cb22-2"><a href="#cb22-2"></a>W <span class="ot">&lt;-</span> W <span class="sc">/</span> <span class="fu">array</span>(<span class="fu">apply</span>(W, <span class="dv">1</span>, sum), <span class="at">dim =</span> <span class="fu">dim</span>(W))</span>
<span id="cb22-3"><a href="#cb22-3"></a><span class="fu">image</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span><span class="sc">:</span>n, W, <span class="at">col =</span> <span class="fu">cols</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-16-3.png" width="576"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># Contiguity matrix</span></span>
<span id="cb23-2"><a href="#cb23-2"></a>W <span class="ot">&lt;-</span> <span class="fu">nb2mat</span>(<span class="fu">poly2nb</span>(B), <span class="at">style =</span> <span class="st">"B"</span>)</span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="fu">image</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span><span class="sc">:</span>n, W, <span class="at">col =</span> <span class="fu">cols</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-16-4.png" width="576"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># Contiguity matrix (row-standardised)</span></span>
<span id="cb24-2"><a href="#cb24-2"></a>W <span class="ot">&lt;-</span> <span class="fu">nb2mat</span>(<span class="fu">poly2nb</span>(B), <span class="at">style =</span> <span class="st">"W"</span>)</span>
<span id="cb24-3"><a href="#cb24-3"></a><span class="fu">image</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="dv">1</span><span class="sc">:</span>n, W, <span class="at">col =</span> <span class="fu">cols</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-16-5.png" width="576"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a>W_list <span class="ot">&lt;-</span> <span class="fu">poly2nb</span>(B)</span>
<span id="cb25-2"><a href="#cb25-2"></a><span class="fu">plot</span>(B, <span class="at">border =</span> <span class="st">"lightgrey"</span>) </span>
<span id="cb25-3"><a href="#cb25-3"></a><span class="fu">plot</span>(B_thin, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd =</span> <span class="dv">1</span>)</span>
<span id="cb25-4"><a href="#cb25-4"></a><span class="fu">plot</span>(W_list, <span class="fu">coordinates</span>(B), <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"darkblue"</span>, </span>
<span id="cb25-5"><a href="#cb25-5"></a>     <span class="at">lwd =</span> <span class="dv">2</span>, <span class="co"># 10*apply(W, 1, max),</span></span>
<span id="cb25-6"><a href="#cb25-6"></a>     <span class="at">cex =</span> <span class="fl">0.2</span><span class="sc">*</span><span class="fu">apply</span>(W, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="fu">sum</span>(x<span class="sc">&gt;</span><span class="dv">0</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-16-6.png" width="576"></p>
</figure>
</div>
</div>
</div>
</section>
<section class="slide level2">

<h3 data-number="2.2.1" id="dynamic-spatial-autoregressive-model"><span class="header-section-number">2.2.1</span> Dynamic Spatial Autoregressive Model</h3>
<p>There are different ways to model the spatial dependence (e.g., spatial lag model, spatial error model, Manski model, etc.); for an overview see <span class="citation" data-cites="Elhorst10">Elhorst (<a href="#/references" role="doc-biblioref" onclick="">2010</a>)</span> .</p>
<div class="fragment">
<p>For instance, a dynamic spatiotemporal autoregressive model is defined as <span class="math display">\[\begin{equation}
    \boldsymbol{Y}_t = \mathbf{X}_t \boldsymbol{\beta} + \gamma \boldsymbol{Y}_{t-1} + \rho \mathbf{W} \boldsymbol{Y}_t  + \boldsymbol{\varepsilon}_t \, .
\end{equation}\]</span></p>
</div>
<div class="fragment">
<p>Reduced form: <span class="math display">\[\begin{eqnarray*}
    \boldsymbol{Y}_t &amp; = &amp; \mathbf{X}_t \boldsymbol{\beta} + \gamma \boldsymbol{Y}_{t-1} + \rho \mathbf{W} \boldsymbol{Y}_t  + \boldsymbol{\varepsilon}_t \, \\
                     &amp; = &amp; (\mathbf{I} - \rho \mathbf{W})^{-1} \left(\mathbf{X}_t \boldsymbol{\beta} + \gamma \boldsymbol{Y}_{t-1} + \boldsymbol{\varepsilon}_t\right) \,
\end{eqnarray*}\]</span></p>
<p>If <span class="math inline">\(\mathbf{I} - \rho \mathbf{W}\)</span> is non-singular for all possible values of <span class="math inline">\(\rho\)</span>, the process is well-defined (note: this is the motivation why the row-standardisation is popular)</p>
</div>
<div class="fragment">
<p>Following the notation above and assuming a Gaussian error process, the model can be rewritten as <span class="math display">\[\begin{eqnarray*}
    \boldsymbol{\mu}_t &amp; = &amp; (\mu_t(\boldsymbol{s}_1), \ldots, \mu_t(\boldsymbol{s}_n))' &amp; = &amp; (\mathbf{I} - \rho \mathbf{W})^{-1} \left( \mathbf{X}_t \boldsymbol{\beta} + \gamma \boldsymbol{Y}_{t-1}\right) \, , \\
    \boldsymbol{\varepsilon}_t  &amp; = &amp; (\varepsilon_t(\boldsymbol{s}_1), \ldots, \varepsilon_t(\boldsymbol{s}_n))' &amp; \sim  &amp; N_n(\boldsymbol{0}, (\mathbf{I} - \rho \mathbf{W})^{-1} \mathbf{\Sigma}_{\varepsilon} (\mathbf{I} - \rho \mathbf{W}')^{-1} ) \, .
\end{eqnarray*}\]</span></p>
</div>
</section>
<section class="slide level2">

<h3 data-number="2.2.2" id="network-models"><span class="header-section-number">2.2.2</span> Network Models</h3>
<p>Let <span class="math inline">\(G = (V, E)\)</span> be graph (network) consisting of a set of vertices, or nodes, <span class="math inline">\(V = \{v_1, \ldots, v_n\}\)</span> and a set of edges <span class="math inline">\(E \subseteq \{(v_i,v_j) : (v_i,v_j) \in V^2\}\)</span>. A detailed overview about the statistical analysis of networks can be found in <span class="citation" data-cites="kolaczyk2010network">Kolaczyk (<a href="#/references" role="doc-biblioref" onclick="">2010</a>)</span> or <span class="citation" data-cites="kolaczyk2014statistical">Kolaczyk and Csrdi (<a href="#/references" role="doc-biblioref" onclick="">2014</a>)</span>.</p>
<p>The weight matrix <span class="math inline">\(\mathbf{W}\)</span> does not have to be considered in a strict geographical sense, but can also be seen as adjacency matrix. That is, <span class="math display">\[\begin{equation*}
w_{ij} = \left\{
\begin{array}{cc}
1 &amp; \text{if nodes $i$ and $j$ are connected by an edge,} \\
0 &amp; \text{otherwise.}
\end{array}
\right.
\end{equation*}\]</span></p>
<p>In this way, <strong>processes on networks</strong> can also be modelled with spatial/spatiotemporal autoregression techniques.</p>
</section>
<section id="model-selection" class="slide level2" data-number="2.3">
<h2><span class="header-section-number">2.3</span> Model Selection</h2>
<p>Example: Consider a linear regression model <span class="math inline">\(\boldsymbol{Y} = \mathbf{X} \,\boldsymbol{\beta} + \boldsymbol{\varepsilon}\)</span> with</p>
<ul>
<li><span class="math inline">\(\mathbf{X}\)</span> known <span class="math inline">\((n,p+1)\)</span>-dimensional matrix with <span class="math inline">\(n \ge p+1\)</span></li>
<li><span class="math inline">\(E(\boldsymbol{\varepsilon}) = \boldsymbol{0}\)</span></li>
<li><span class="math inline">\(Cov(\boldsymbol{\varepsilon}) = \sigma^2 \mathbf{I}\)</span>, where <span class="math inline">\(\mathbf{I} = \mbox{diag}(1,1,...,1)\)</span>.</li>
</ul>
<p>Moreover, let <span class="math inline">\(\hat{\boldsymbol{Y}} = \mathbf{X} \,\hat{\boldsymbol{\beta}}\)</span> be the model predictions and <span class="math inline">\(\bar Y= \frac{1}{n}\,\sum\limits_{i=1}^n Y_i\)</span>.</p>
<div class="fragment">
<p><strong>Problem 1:</strong> How well does the selected regression model describe the data? <span class="math inline">\(\rightsquigarrow\)</span> Measure for the goodness of fit of the model</p>
</div>
<div class="fragment">
<ul>
<li>In-sample vs.&nbsp;out-of-sample fit</li>
</ul>
<p>In-sample predictions use the same observation for parameter estimation (i.e., to obtain <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>) and the predictions, whereas out-of-sample predictions use different data sets (i.e., the predicted observations were not part of the estimation data set).</p>
<p>Common strategies for out-of-sample predictions: 1) training and testing data set (optionally + validation set), 2) cross validation (random CV, LooCV, <span class="math inline">\(k\)</span>-fold CV, Block CV). Note that random CV strategies are not suitable for dependent data.</p>
</div>
<div class="fragment">
<ul>
<li>Coefficient of determination <span class="math inline">\(R^2\)</span></li>
</ul>
<p><span class="math display">\[\begin{alignat*}{3}
\sum_{i=1}^n \big(Y_i-\bar Y\big)^2
   &amp; = \sum_{i=1}^n \big(Y_i-\widehat Y_i\big)^2
   &amp;&amp; + \sum_{i=1}^n \big(\widehat Y_i-\bar Y\big)^2 \\
\text{Total sum of squares}
   &amp; = \text{unexplained variance}
   &amp;&amp; + \text{explained variance by the model}
\end{alignat*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
R^2 = \frac{\sum_{i=1}^n \big(\widehat Y_i-\bar Y\big)^2}
            {\sum_{i=1}^n \big(Y_i-\bar Y\big)^2}
= 1\,-\, \frac{\sum_{i=1}^n \big(Y_i-\widehat Y_i\big)^2}
                   {\sum_{i=1}^n \big(Y_i-\bar Y\big)^2}                 
   =  1\,-\, \frac{\text{Residuals sum of squares $SS_{res}$}}
                   {\text{Total sum of squares $SS_{tot}$}}  
\end{equation*}\]</span></p>
<p>Measure for the proportion of variation in the dependent variable that is explained by the model (i.e., the predictors and structural assumption of the model). For in-sample predictions, <span class="math inline">\(R^2\)</span> ranges from zero to one, where <span class="math inline">\(R^2 = 0\)</span> if <span class="math inline">\(\hat{Y}_i = \bar{Y}\)</span> for all <span class="math inline">\(i\)</span> and <span class="math inline">\(R^2 = 1\)</span> if <span class="math inline">\(\hat{Y}_i = Y_i\)</span> for all <span class="math inline">\(i\)</span>. Note that this is not necessarily the case if the <span class="math inline">\(R^2\)</span> is computed for out-of-sample data (i.e., the data set for estimation of the model coefficients, training set, is different from the data set used for validation).</p>
<p><strong>However,</strong> <span class="math inline">\(R^2\)</span> grows with increasing number of factors. Thus, <span class="math inline">\(R^2\)</span> cannot be used for model selection.</p>
</div>
<div class="fragment">
<ul>
<li>Adjusted coefficient of determination <span class="math inline">\(\bar R^2\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation*}
\bar R(k)^2 = 1\,-\,\frac{\widehat\sigma(k)^2}
             {\frac{1}{n-1}\,\sum_{i=1}^n \big(Y_i-\bar
             Y\big)^2}
= 1 \,-\, \frac{\frac{1}{n-k-1}\,\sum (\widehat Y_i-Y_i)^2}{\frac{1}{n-1}\,\sum (Y_i-\bar Y)^2}
= 1 \,-\, \frac{n-1}{n-k-1}\,\big(1-R(k)^2\big) ,
\end{equation*}\]</span> where <span class="math inline">\(k\)</span> is the implied model order (i.e., number of unknown parameters).</p>
</div>
<div class="fragment">
<ul>
<li>Prediction accuracy <span class="math inline">\(RMSE\)</span> (root mean square error), <span class="math inline">\(MAE\)</span> (mean absolute errors), <span class="math inline">\(MAD\)</span> (median absolute deviation)</li>
</ul>
<p><span class="math display">\[\begin{alignat*}{3}
RMSE &amp; = &amp; \sqrt{\frac{1}{n} \sum_{i = 1}^{n} (\hat{Y}_i - Y_i)^2} \\
MAE &amp; = &amp; \frac{1}{n} \sum_{i = 1}^{n} | \hat{Y}_i - Y_i |\\
MAD &amp; = &amp; \text{median}(| \hat{Y}_i - Y_i |)
\end{alignat*}\]</span></p>
<p>Measure for the average/median deviation of the predicted values from the observed values (in the same units as the measurements of the response variable). In this sense, they provide more/different information compared to <span class="math inline">\(R^2\)</span>.</p>
</div>
</section>
<section class="slide level2">

<p><strong>Problem 2:</strong> What complexity does the model need to have in order to best describe the data? <span class="math inline">\(\rightsquigarrow\)</span> Selection of relevant factors (regressors) or the model order/complexity</p>
<div class="fragment">
<ul>
<li>Model selection based on <span class="math inline">\(\bar R^2\)</span></li>
</ul>
<p>Procedure: determine <span class="math inline">\(\bar R^2\)</span> for all possible combinations of the regressors (i.e., <span class="math inline">\(2^k\)</span> combinations) and choose the model, which has the highest <span class="math inline">\(\bar R^2\)</span>. Instead of considering all combinations, step-wise procedure could be applied (forward/backward/both-sided). Maximising <span class="math inline">\(\bar R^2\)</span> is equivalent to minimising <span class="math inline">\(\widehat\sigma^2(k)\)</span>. <strong>However,</strong> the procedure is inconsistent (i.e., the correct model is not selected with probability one when <span class="math inline">\(n\)</span> is approaching infinity)</p>
</div>
<div class="fragment">
<ul>
<li>Model selection based on cross-validation</li>
</ul>
<p>Procedure: select a suitable cross-validation procedure to split your data set, then determine average <span class="math inline">\(RMSE\)</span>, <span class="math inline">\(MAE\)</span> across your testing samples and select the model which minimise the <span class="math inline">\(RMSE\)</span>, <span class="math inline">\(MAE\)</span>. <strong>Drawback:</strong> computationally expensive (repeated model estimation for all folds and each considered model)</p>
</div>
<div class="fragment">
<ul>
<li>Information criteria</li>
</ul>
<p>Information criteria contain two opposing terms: goodness-of-fit term <span class="math inline">\(\widehat\sigma^2(k)\)</span> and penalty term based on the number of estimated paramters</p>
<p><span class="math display">\[\begin{eqnarray*}
  AIC(k) &amp; =  &amp; \ln \widehat\sigma(k)^2 \,+\, k\,\frac{2}{n}\\
    BIC(k) &amp; =  &amp; \ln \widehat\sigma(k)^2 \,+\, k\,\frac{\ln n}{n}
\end{eqnarray*}\]</span></p>
<p>Procedure: determine information criteria for all possible combinations of the regressor and choose the model, which has the minimal information criteria.</p>
<p>While AIC is better for choosing a prediction model (asymptotically equivalent to cross-validation), BIC performs better when explaining the underlying data (because it consistently finds the underlying data generating process, i.e., the true model).</p>
</div>
<div class="fragment">
<ul>
<li>Combination of model selection and estimation <span class="math inline">\(\leadsto\)</span> penalised regression</li>
</ul>
</div>
</section></section>
<section>
<section id="regularised-estimation-methods" class="title-slide slide level1 center" data-number="3">
<h1><span class="header-section-number">3</span> Regularised Estimation Methods</h1>

</section>
<section id="overview" class="slide level2" data-number="3.1">
<h2><span class="header-section-number">3.1</span> Overview</h2>
<p><strong>Idea:</strong> Combine model selection and estimation in one step. Penalised estimation procedures can be used to shrink the model parameters towards a pre-specified target. If this target value is chosen to be zero, which means that the parameter is excluded from the model if the estimated coefficient is equal to zero <span class="math inline">\(\leadsto\)</span> procedures are useful for model selection.</p>
<p>Example: Linear regression model</p>
</section>
<section id="lasso" class="slide level2" data-number="3.2">
<h2><span class="header-section-number">3.2</span> LASSO</h2>
<p>Least absolute shrinkage and selection operator  LASSO</p>
<p>Minimise <span class="math inline">\((\boldsymbol{Y} - \beta_0 \boldsymbol{1} - \mathbf{X} \, \boldsymbol{\beta})^\prime\, (\boldsymbol{Y} - \beta_0 \boldsymbol{1} - \mathbf{X} \, \boldsymbol{\beta})\)</span> subject to <span class="math inline">\(||\boldsymbol{\beta}||_1 \leq t\)</span> with respect to <span class="math inline">\((\beta_0, \boldsymbol{\beta})' \in \mathbb{R}^{p+1}\)</span>.</p>
<p>The parameter <span class="math inline">\(t\)</span> controls the degree of regularisation. Moreover, <span class="math inline">\(|| \cdot ||_1\)</span> denotes the Manhattan norm. Note that the intercept <span class="math inline">\(\beta_0\)</span> is typically not included in the constraint (i.e., <span class="math inline">\(\mathbf{X}\)</span> does not include a columns of ones).</p>
<div class="fragment">
<p>With <span class="math inline">\(\hat{\beta}_0 = (\bar{Y} - \bar{\boldsymbol{X}}' \boldsymbol{\beta})\)</span>, we get that <span class="math display">\[\begin{equation*}
    Y_i - \hat{\beta}_0 - \boldsymbol{X}_i' \boldsymbol{\beta} = Y_i - (\bar{Y} - \bar{\boldsymbol{X}}' \boldsymbol{\beta}) - \boldsymbol{X}' \boldsymbol{\beta} = (Y_i - \bar{Y}) - (\boldsymbol{X} - \bar{\boldsymbol{X}})'\boldsymbol{\beta} \,
\end{equation*}\]</span> with <span class="math inline">\(\boldsymbol{X} = (X_{i1}, ..., X_{ip})'\)</span> and <span class="math inline">\(\bar{\boldsymbol{X}} = (\bar{X}_{1}, ..., \bar{X}_{p})'\)</span>. Thus, all variables are typically demeaned and <span class="math inline">\(\beta_0\)</span> is excluded from the regression. Moreover, to obtained an equal degree of penalisation for each variable (then the result does not depend on the variance of the regressors), the regressors are typically standardised.</p>
</div>
<div class="fragment">
<p>Then, the minimisation is equivalent to the Lagrangian form <span class="math display">\[\begin{equation*}
    \hat{\boldsymbol{\beta}}_{\text{Lasso}}(\lambda) = \arg \min_{\boldsymbol{\beta} \in \mathbb{R}^{p}} \frac{1}{n} (\boldsymbol{Y} - \mathbf{X} \, \boldsymbol{\beta})^\prime (\boldsymbol{Y} - \mathbf{X} \, \boldsymbol{\beta}) + \lambda ||\beta||_1
\end{equation*}\]</span> with regularisation parameter <span class="math inline">\(\lambda \geq 0\)</span>.</p>
</div>
<div class="fragment">
<p>Note:</p>
<ul>
<li>Choice of the regularisation parameter <span class="math inline">\(\lambda\)</span> (controls both the degree of shrinkage and model selection): minimise a suitable goodness-of-fit measure in a cross-validation study and choose <span class="math inline">\(\lambda^*\)</span> such that this measure is optimal (e.g., minimise prediction RMSE, AIC/BIC is minimal, etc.)</li>
<li>The objective function is not differentiable: numerical methods for optimisation must be applied, e.g., coordinate descent algorithms, least-angle regression (LARS), or other methods</li>
<li>For LASSO, there are strong assumptions such that the method is selection consistent (i.e., asymptotically selecting the true model), e.g., if the regressors are correlated LASSO is usually not selection consistent</li>
<li>LASSO can also be applied if <span class="math inline">\(rank(\mathbf{X}) &gt; p\)</span> (i.e., high-dimensional case with more regressors than observations), but then <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is not unique but only <span class="math inline">\(\mathbf{X}\hat{\boldsymbol{\beta}}\)</span></li>
</ul>
</div>
</section>
<section id="implementation-in-r" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in R</h2>
<div class="sourceCode" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb26-1" class="hljs-ln-code"><a href="#cb26-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb26-2" class="hljs-ln-code"><a href="#cb26-2"></a></span>
<span id="cb26-3" class="hljs-ln-code"><a href="#cb26-3"></a><span class="co"># Load the sample data</span></span>
<span id="cb26-4" class="hljs-ln-code"><a href="#cb26-4"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb26-5" class="hljs-ln-code"><a href="#cb26-5"></a></span>
<span id="cb26-6" class="hljs-ln-code"><a href="#cb26-6"></a><span class="fu">dim</span>(mtcars)</span>
<span id="cb26-7" class="hljs-ln-code"><a href="#cb26-7"></a><span class="fu">head</span>(mtcars)</span>
<span id="cb26-8" class="hljs-ln-code"><a href="#cb26-8"></a></span>
<span id="cb26-9" class="hljs-ln-code"><a href="#cb26-9"></a><span class="co"># Convert the data to matrices</span></span>
<span id="cb26-10" class="hljs-ln-code"><a href="#cb26-10"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb26-11" class="hljs-ln-code"><a href="#cb26-11"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="dv">1</span>])</span>
<span id="cb26-12" class="hljs-ln-code"><a href="#cb26-12"></a></span>
<span id="cb26-13" class="hljs-ln-code"><a href="#cb26-13"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(X)</span>
<span id="cb26-14" class="hljs-ln-code"><a href="#cb26-14"></a></span>
<span id="cb26-15" class="hljs-ln-code"><a href="#cb26-15"></a><span class="co"># Fit the LASSO model</span></span>
<span id="cb26-16" class="hljs-ln-code"><a href="#cb26-16"></a></span>
<span id="cb26-17" class="hljs-ln-code"><a href="#cb26-17"></a><span class="co"># Plot the lambda path</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-in-r-1" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in R</h2>
<div class="sourceCode" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb27-1" class="hljs-ln-code"><a href="#cb27-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb27-2" class="hljs-ln-code"><a href="#cb27-2"></a></span>
<span id="cb27-3" class="hljs-ln-code"><a href="#cb27-3"></a><span class="co"># Load the sample data</span></span>
<span id="cb27-4" class="hljs-ln-code"><a href="#cb27-4"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb27-5" class="hljs-ln-code"><a href="#cb27-5"></a></span>
<span id="cb27-6" class="hljs-ln-code"><a href="#cb27-6"></a><span class="fu">dim</span>(mtcars)</span>
<span id="cb27-7" class="hljs-ln-code"><a href="#cb27-7"></a><span class="fu">head</span>(mtcars)</span>
<span id="cb27-8" class="hljs-ln-code"><a href="#cb27-8"></a></span>
<span id="cb27-9" class="hljs-ln-code"><a href="#cb27-9"></a><span class="co"># Convert the data to matrices</span></span>
<span id="cb27-10" class="hljs-ln-code"><a href="#cb27-10"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb27-11" class="hljs-ln-code"><a href="#cb27-11"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="dv">1</span>])</span>
<span id="cb27-12" class="hljs-ln-code"><a href="#cb27-12"></a></span>
<span id="cb27-13" class="hljs-ln-code"><a href="#cb27-13"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(X)</span>
<span id="cb27-14" class="hljs-ln-code"><a href="#cb27-14"></a></span>
<span id="cb27-15" class="hljs-ln-code"><a href="#cb27-15"></a><span class="co"># Fit the LASSO model</span></span>
<span id="cb27-16" class="hljs-ln-code"><a href="#cb27-16"></a>fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">intercept =</span> <span class="cn">TRUE</span>)</span>
<span id="cb27-17" class="hljs-ln-code"><a href="#cb27-17"></a></span>
<span id="cb27-18" class="hljs-ln-code"><a href="#cb27-18"></a><span class="co"># Plot the lambda path</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-in-r-2" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in R</h2>
<div class="sourceCode" id="cb28"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb28-1" class="hljs-ln-code"><a href="#cb28-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb28-2" class="hljs-ln-code"><a href="#cb28-2"></a></span>
<span id="cb28-3" class="hljs-ln-code"><a href="#cb28-3"></a><span class="co"># Load the sample data</span></span>
<span id="cb28-4" class="hljs-ln-code"><a href="#cb28-4"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb28-5" class="hljs-ln-code"><a href="#cb28-5"></a></span>
<span id="cb28-6" class="hljs-ln-code"><a href="#cb28-6"></a><span class="fu">dim</span>(mtcars)</span>
<span id="cb28-7" class="hljs-ln-code"><a href="#cb28-7"></a><span class="fu">head</span>(mtcars)</span>
<span id="cb28-8" class="hljs-ln-code"><a href="#cb28-8"></a></span>
<span id="cb28-9" class="hljs-ln-code"><a href="#cb28-9"></a><span class="co"># Convert the data to matrices</span></span>
<span id="cb28-10" class="hljs-ln-code"><a href="#cb28-10"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb28-11" class="hljs-ln-code"><a href="#cb28-11"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="dv">1</span>])</span>
<span id="cb28-12" class="hljs-ln-code"><a href="#cb28-12"></a></span>
<span id="cb28-13" class="hljs-ln-code"><a href="#cb28-13"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(X)</span>
<span id="cb28-14" class="hljs-ln-code"><a href="#cb28-14"></a></span>
<span id="cb28-15" class="hljs-ln-code"><a href="#cb28-15"></a><span class="co"># Fit the LASSO model</span></span>
<span id="cb28-16" class="hljs-ln-code"><a href="#cb28-16"></a>fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">intercept =</span> <span class="cn">TRUE</span>)</span>
<span id="cb28-17" class="hljs-ln-code"><a href="#cb28-17"></a></span>
<span id="cb28-18" class="hljs-ln-code"><a href="#cb28-18"></a><span class="co"># Plot the lambda path</span></span>
<span id="cb28-19" class="hljs-ln-code"><a href="#cb28-19"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-in-r-3" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in R</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb29-2"><a href="#cb29-2"></a></span>
<span id="cb29-3"><a href="#cb29-3"></a><span class="co"># Load the sample data</span></span>
<span id="cb29-4"><a href="#cb29-4"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb29-5"><a href="#cb29-5"></a></span>
<span id="cb29-6"><a href="#cb29-6"></a><span class="fu">dim</span>(mtcars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 32 11</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a><span class="fu">head</span>(mtcars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>
</div>
</div>
</section>
<section id="implementation-in-r-4" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in R</h2>
<div class="cell columns column-output-location" data-layout-align="center">
<div class="column">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode r hljs"><span id="cb33-1" class="hljs-ln-code"><a href="#cb33-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb33-2" class="hljs-ln-code"><a href="#cb33-2"></a></span>
<span id="cb33-3" class="hljs-ln-code"><a href="#cb33-3"></a><span class="co"># Load the sample data</span></span>
<span id="cb33-4" class="hljs-ln-code"><a href="#cb33-4"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb33-5" class="hljs-ln-code"><a href="#cb33-5"></a></span>
<span id="cb33-6" class="hljs-ln-code"><a href="#cb33-6"></a><span class="co"># Convert the data to matrices</span></span>
<span id="cb33-7" class="hljs-ln-code"><a href="#cb33-7"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb33-8" class="hljs-ln-code"><a href="#cb33-8"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="dv">1</span>])</span>
<span id="cb33-9" class="hljs-ln-code"><a href="#cb33-9"></a></span>
<span id="cb33-10" class="hljs-ln-code"><a href="#cb33-10"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(X)</span>
<span id="cb33-11" class="hljs-ln-code"><a href="#cb33-11"></a></span>
<span id="cb33-12" class="hljs-ln-code"><a href="#cb33-12"></a><span class="co"># Fit the LASSO model</span></span>
<span id="cb33-13" class="hljs-ln-code"><a href="#cb33-13"></a>fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">intercept =</span> <span class="cn">TRUE</span>)</span>
<span id="cb33-14" class="hljs-ln-code"><a href="#cb33-14"></a></span>
<span id="cb33-15" class="hljs-ln-code"><a href="#cb33-15"></a><span class="co"># Plot the lambda path</span></span>
<span id="cb33-16" class="hljs-ln-code"><a href="#cb33-16"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-18-1.png" width="864"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="implementation-in-python" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in Python</h2>
<div class="sourceCode" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode python hljs"><span id="cb34-1" class="hljs-ln-code"><a href="#cb34-1"></a><span class="co"># Load the required libraries</span></span>
<span id="cb34-2" class="hljs-ln-code"><a href="#cb34-2"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> lasso_path</span>
<span id="cb34-3" class="hljs-ln-code"><a href="#cb34-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb34-4" class="hljs-ln-code"><a href="#cb34-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-5" class="hljs-ln-code"><a href="#cb34-5"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb34-6" class="hljs-ln-code"><a href="#cb34-6"></a><span class="im">from</span> itertools <span class="im">import</span> cycle</span>
<span id="cb34-7" class="hljs-ln-code"><a href="#cb34-7"></a></span>
<span id="cb34-8" class="hljs-ln-code"><a href="#cb34-8"></a><span class="co"># Load the sample data</span></span>
<span id="cb34-9" class="hljs-ln-code"><a href="#cb34-9"></a>cars <span class="op">=</span> pd.read_csv(<span class="st">'sources/mtcars.csv'</span>, index_col <span class="op">=</span> <span class="dv">0</span>, header <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb34-10" class="hljs-ln-code"><a href="#cb34-10"></a></span>
<span id="cb34-11" class="hljs-ln-code"><a href="#cb34-11"></a>cars.shape</span>
<span id="cb34-12" class="hljs-ln-code"><a href="#cb34-12"></a>cars.head()</span>
<span id="cb34-13" class="hljs-ln-code"><a href="#cb34-13"></a></span>
<span id="cb34-14" class="hljs-ln-code"><a href="#cb34-14"></a>lambdas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="fl">4.5</span>, <span class="fl">0.9</span>, <span class="dv">100</span>)</span>
<span id="cb34-15" class="hljs-ln-code"><a href="#cb34-15"></a></span>
<span id="cb34-16" class="hljs-ln-code"><a href="#cb34-16"></a><span class="co"># Split the data into features and target</span></span>
<span id="cb34-17" class="hljs-ln-code"><a href="#cb34-17"></a>X <span class="op">=</span> cars.drop(<span class="st">'mpg'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb34-18" class="hljs-ln-code"><a href="#cb34-18"></a>y <span class="op">=</span> cars[<span class="st">'mpg'</span>]</span>
<span id="cb34-19" class="hljs-ln-code"><a href="#cb34-19"></a></span>
<span id="cb34-20" class="hljs-ln-code"><a href="#cb34-20"></a><span class="co"># Standardize data</span></span>
<span id="cb34-21" class="hljs-ln-code"><a href="#cb34-21"></a>X <span class="op">-=</span> X.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb34-22" class="hljs-ln-code"><a href="#cb34-22"></a>X <span class="op">/=</span> X.std(axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb34-23" class="hljs-ln-code"><a href="#cb34-23"></a></span>
<span id="cb34-24" class="hljs-ln-code"><a href="#cb34-24"></a><span class="co"># Use lasso_path to compute a coefficient path</span></span>
<span id="cb34-25" class="hljs-ln-code"><a href="#cb34-25"></a></span>
<span id="cb34-26" class="hljs-ln-code"><a href="#cb34-26"></a><span class="co"># Plot coefficients against lambda</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-in-python-1" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in Python</h2>
<div class="sourceCode" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode python hljs"><span id="cb35-1" class="hljs-ln-code"><a href="#cb35-1"></a><span class="co"># Load the required libraries</span></span>
<span id="cb35-2" class="hljs-ln-code"><a href="#cb35-2"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> lasso_path</span>
<span id="cb35-3" class="hljs-ln-code"><a href="#cb35-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb35-4" class="hljs-ln-code"><a href="#cb35-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb35-5" class="hljs-ln-code"><a href="#cb35-5"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-6" class="hljs-ln-code"><a href="#cb35-6"></a><span class="im">from</span> itertools <span class="im">import</span> cycle</span>
<span id="cb35-7" class="hljs-ln-code"><a href="#cb35-7"></a></span>
<span id="cb35-8" class="hljs-ln-code"><a href="#cb35-8"></a><span class="co"># Load the sample data</span></span>
<span id="cb35-9" class="hljs-ln-code"><a href="#cb35-9"></a>cars <span class="op">=</span> pd.read_csv(<span class="st">'sources/mtcars.csv'</span>, index_col <span class="op">=</span> <span class="dv">0</span>, header <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb35-10" class="hljs-ln-code"><a href="#cb35-10"></a></span>
<span id="cb35-11" class="hljs-ln-code"><a href="#cb35-11"></a>cars.shape</span>
<span id="cb35-12" class="hljs-ln-code"><a href="#cb35-12"></a>cars.head()</span>
<span id="cb35-13" class="hljs-ln-code"><a href="#cb35-13"></a></span>
<span id="cb35-14" class="hljs-ln-code"><a href="#cb35-14"></a>lambdas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="fl">4.5</span>, <span class="fl">0.9</span>, <span class="dv">100</span>)</span>
<span id="cb35-15" class="hljs-ln-code"><a href="#cb35-15"></a></span>
<span id="cb35-16" class="hljs-ln-code"><a href="#cb35-16"></a><span class="co"># Split the data into features and target</span></span>
<span id="cb35-17" class="hljs-ln-code"><a href="#cb35-17"></a>X <span class="op">=</span> cars.drop(<span class="st">'mpg'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-18" class="hljs-ln-code"><a href="#cb35-18"></a>y <span class="op">=</span> cars[<span class="st">'mpg'</span>]</span>
<span id="cb35-19" class="hljs-ln-code"><a href="#cb35-19"></a></span>
<span id="cb35-20" class="hljs-ln-code"><a href="#cb35-20"></a><span class="co"># Standardize data</span></span>
<span id="cb35-21" class="hljs-ln-code"><a href="#cb35-21"></a>X <span class="op">-=</span> X.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-22" class="hljs-ln-code"><a href="#cb35-22"></a>X <span class="op">/=</span> X.std(axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb35-23" class="hljs-ln-code"><a href="#cb35-23"></a></span>
<span id="cb35-24" class="hljs-ln-code"><a href="#cb35-24"></a><span class="co"># Use lasso_path to compute a coefficient path</span></span>
<span id="cb35-25" class="hljs-ln-code"><a href="#cb35-25"></a>alphas_lasso, coef_path, _ <span class="op">=</span> lasso_path(X, y, alphas <span class="op">=</span> lambdas)</span>
<span id="cb35-26" class="hljs-ln-code"><a href="#cb35-26"></a></span>
<span id="cb35-27" class="hljs-ln-code"><a href="#cb35-27"></a><span class="co"># Plot coefficients against lambda</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-in-python-2" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in Python</h2>
<div class="sourceCode" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode python hljs"><span id="cb36-1" class="hljs-ln-code"><a href="#cb36-1"></a><span class="co"># Load the required libraries</span></span>
<span id="cb36-2" class="hljs-ln-code"><a href="#cb36-2"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> lasso_path</span>
<span id="cb36-3" class="hljs-ln-code"><a href="#cb36-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb36-4" class="hljs-ln-code"><a href="#cb36-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-5" class="hljs-ln-code"><a href="#cb36-5"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-6" class="hljs-ln-code"><a href="#cb36-6"></a><span class="im">from</span> itertools <span class="im">import</span> cycle</span>
<span id="cb36-7" class="hljs-ln-code"><a href="#cb36-7"></a></span>
<span id="cb36-8" class="hljs-ln-code"><a href="#cb36-8"></a><span class="co"># Load the sample data</span></span>
<span id="cb36-9" class="hljs-ln-code"><a href="#cb36-9"></a>cars <span class="op">=</span> pd.read_csv(<span class="st">'sources/mtcars.csv'</span>, index_col <span class="op">=</span> <span class="dv">0</span>, header <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb36-10" class="hljs-ln-code"><a href="#cb36-10"></a></span>
<span id="cb36-11" class="hljs-ln-code"><a href="#cb36-11"></a>cars.shape</span>
<span id="cb36-12" class="hljs-ln-code"><a href="#cb36-12"></a>cars.head()</span>
<span id="cb36-13" class="hljs-ln-code"><a href="#cb36-13"></a></span>
<span id="cb36-14" class="hljs-ln-code"><a href="#cb36-14"></a>lambdas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="fl">4.5</span>, <span class="fl">0.9</span>, <span class="dv">100</span>)</span>
<span id="cb36-15" class="hljs-ln-code"><a href="#cb36-15"></a></span>
<span id="cb36-16" class="hljs-ln-code"><a href="#cb36-16"></a><span class="co"># Split the data into features and target</span></span>
<span id="cb36-17" class="hljs-ln-code"><a href="#cb36-17"></a>X <span class="op">=</span> cars.drop(<span class="st">'mpg'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-18" class="hljs-ln-code"><a href="#cb36-18"></a>y <span class="op">=</span> cars[<span class="st">'mpg'</span>]</span>
<span id="cb36-19" class="hljs-ln-code"><a href="#cb36-19"></a></span>
<span id="cb36-20" class="hljs-ln-code"><a href="#cb36-20"></a><span class="co"># Standardize data</span></span>
<span id="cb36-21" class="hljs-ln-code"><a href="#cb36-21"></a>X <span class="op">-=</span> X.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb36-22" class="hljs-ln-code"><a href="#cb36-22"></a>X <span class="op">/=</span> X.std(axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb36-23" class="hljs-ln-code"><a href="#cb36-23"></a></span>
<span id="cb36-24" class="hljs-ln-code"><a href="#cb36-24"></a><span class="co"># Use lasso_path to compute a coefficient path</span></span>
<span id="cb36-25" class="hljs-ln-code"><a href="#cb36-25"></a>alphas_lasso, coef_path, _ <span class="op">=</span> lasso_path(X, y, alphas <span class="op">=</span> lambdas)</span>
<span id="cb36-26" class="hljs-ln-code"><a href="#cb36-26"></a></span>
<span id="cb36-27" class="hljs-ln-code"><a href="#cb36-27"></a><span class="co"># Plot coefficients against lambda</span></span>
<span id="cb36-28" class="hljs-ln-code"><a href="#cb36-28"></a>plt.figure()</span>
<span id="cb36-29" class="hljs-ln-code"><a href="#cb36-29"></a>colors <span class="op">=</span> cycle([<span class="st">"b"</span>, <span class="st">"r"</span>, <span class="st">"g"</span>, <span class="st">"c"</span>, <span class="st">"k"</span>])</span>
<span id="cb36-30" class="hljs-ln-code"><a href="#cb36-30"></a><span class="cf">for</span> coefs, c <span class="kw">in</span> <span class="bu">zip</span>(coef_path, colors):</span>
<span id="cb36-31" class="hljs-ln-code"><a href="#cb36-31"></a>    l1 <span class="op">=</span> plt.plot(alphas_lasso, coefs, c <span class="op">=</span> c)</span>
<span id="cb36-32" class="hljs-ln-code"><a href="#cb36-32"></a>plt.xlabel(<span class="st">"Log Lambda"</span>)</span>
<span id="cb36-33" class="hljs-ln-code"><a href="#cb36-33"></a>plt.ylabel(<span class="st">"Coefficients"</span>)</span>
<span id="cb36-34" class="hljs-ln-code"><a href="#cb36-34"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb36-35" class="hljs-ln-code"><a href="#cb36-35"></a>plt.title(<span class="st">"Lasso Coefficient Path"</span>)</span>
<span id="cb36-36" class="hljs-ln-code"><a href="#cb36-36"></a>plt.axis(<span class="st">"tight"</span>)</span>
<span id="cb36-37" class="hljs-ln-code"><a href="#cb36-37"></a></span>
<span id="cb36-38" class="hljs-ln-code"><a href="#cb36-38"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-in-python-3" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in Python</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># Load the required libraries</span></span>
<span id="cb37-2"><a href="#cb37-2"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> lasso_path</span>
<span id="cb37-3"><a href="#cb37-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb37-4"><a href="#cb37-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb37-5"><a href="#cb37-5"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb37-6"><a href="#cb37-6"></a><span class="im">from</span> itertools <span class="im">import</span> cycle</span>
<span id="cb37-7"><a href="#cb37-7"></a></span>
<span id="cb37-8"><a href="#cb37-8"></a><span class="co"># Load the sample data</span></span>
<span id="cb37-9"><a href="#cb37-9"></a>cars <span class="op">=</span> pd.read_csv(<span class="st">'sources/mtcars.csv'</span>, index_col <span class="op">=</span> <span class="dv">0</span>, header <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb37-10"><a href="#cb37-10"></a></span>
<span id="cb37-11"><a href="#cb37-11"></a>cars.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(32, 11)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a>cars.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                    mpg  cyl   disp   hp  drat  ...   qsec  vs  am  gear  carb
model                                           ...                           
Mazda RX4          21.0    6  160.0  110  3.90  ...  16.46   0   1     4     4
Mazda RX4 Wag      21.0    6  160.0  110  3.90  ...  17.02   0   1     4     4
Datsun 710         22.8    4  108.0   93  3.85  ...  18.61   1   1     4     1
Hornet 4 Drive     21.4    6  258.0  110  3.08  ...  19.44   1   0     3     1
Hornet Sportabout  18.7    8  360.0  175  3.15  ...  17.02   0   0     3     2

[5 rows x 11 columns]</code></pre>
</div>
</div>
</section>
<section id="implementation-in-python-4" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Implementation in Python</h2>
<div class="cell columns column-output-location" data-layout-align="center">
<div class="column">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy" data-id="quarto-animate-code"><code class="sourceCode python hljs"><span id="cb41-1" class="hljs-ln-code"><a href="#cb41-1"></a><span class="co"># Load the required libraries</span></span>
<span id="cb41-2" class="hljs-ln-code"><a href="#cb41-2"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> lasso_path</span>
<span id="cb41-3" class="hljs-ln-code"><a href="#cb41-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb41-4" class="hljs-ln-code"><a href="#cb41-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb41-5" class="hljs-ln-code"><a href="#cb41-5"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb41-6" class="hljs-ln-code"><a href="#cb41-6"></a><span class="im">from</span> itertools <span class="im">import</span> cycle</span>
<span id="cb41-7" class="hljs-ln-code"><a href="#cb41-7"></a></span>
<span id="cb41-8" class="hljs-ln-code"><a href="#cb41-8"></a><span class="co"># Load the sample data</span></span>
<span id="cb41-9" class="hljs-ln-code"><a href="#cb41-9"></a>cars <span class="op">=</span> pd.read_csv(<span class="st">'sources/mtcars.csv'</span>, index_col <span class="op">=</span> <span class="dv">0</span>, header <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb41-10" class="hljs-ln-code"><a href="#cb41-10"></a></span>
<span id="cb41-11" class="hljs-ln-code"><a href="#cb41-11"></a>lambdas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="fl">4.5</span>, <span class="fl">0.9</span>, <span class="dv">100</span>)</span>
<span id="cb41-12" class="hljs-ln-code"><a href="#cb41-12"></a></span>
<span id="cb41-13" class="hljs-ln-code"><a href="#cb41-13"></a><span class="co"># Split the data into features and target</span></span>
<span id="cb41-14" class="hljs-ln-code"><a href="#cb41-14"></a>X <span class="op">=</span> cars.drop(<span class="st">'mpg'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb41-15" class="hljs-ln-code"><a href="#cb41-15"></a>y <span class="op">=</span> cars[<span class="st">'mpg'</span>]</span>
<span id="cb41-16" class="hljs-ln-code"><a href="#cb41-16"></a></span>
<span id="cb41-17" class="hljs-ln-code"><a href="#cb41-17"></a><span class="co"># Standardize data</span></span>
<span id="cb41-18" class="hljs-ln-code"><a href="#cb41-18"></a>X <span class="op">-=</span> X.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-19" class="hljs-ln-code"><a href="#cb41-19"></a>X <span class="op">/=</span> X.std(axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb41-20" class="hljs-ln-code"><a href="#cb41-20"></a></span>
<span id="cb41-21" class="hljs-ln-code"><a href="#cb41-21"></a><span class="co"># Use lasso_path to compute a coefficient path</span></span>
<span id="cb41-22" class="hljs-ln-code"><a href="#cb41-22"></a>alphas_lasso, coef_path, _ <span class="op">=</span> lasso_path(X, y, alphas <span class="op">=</span> lambdas)</span>
<span id="cb41-23" class="hljs-ln-code"><a href="#cb41-23"></a></span>
<span id="cb41-24" class="hljs-ln-code"><a href="#cb41-24"></a><span class="co"># Plot coefficients against lambda</span></span>
<span id="cb41-25" class="hljs-ln-code"><a href="#cb41-25"></a>plt.figure()<span class="op">;</span></span>
<span id="cb41-26" class="hljs-ln-code"><a href="#cb41-26"></a>colors <span class="op">=</span> cycle([<span class="st">"b"</span>, <span class="st">"r"</span>, <span class="st">"g"</span>, <span class="st">"c"</span>, <span class="st">"k"</span>])</span>
<span id="cb41-27" class="hljs-ln-code"><a href="#cb41-27"></a><span class="cf">for</span> coefs, c <span class="kw">in</span> <span class="bu">zip</span>(coef_path, colors):</span>
<span id="cb41-28" class="hljs-ln-code"><a href="#cb41-28"></a>    l1 <span class="op">=</span> plt.plot(alphas_lasso, coefs, c <span class="op">=</span> c)<span class="op">;</span></span>
<span id="cb41-29" class="hljs-ln-code"><a href="#cb41-29"></a>plt.xlabel(<span class="st">"Log Lambda"</span>)<span class="op">;</span></span>
<span id="cb41-30" class="hljs-ln-code"><a href="#cb41-30"></a>plt.ylabel(<span class="st">"Coefficients"</span>)<span class="op">;</span></span>
<span id="cb41-31" class="hljs-ln-code"><a href="#cb41-31"></a>plt.xscale(<span class="st">'log'</span>)<span class="op">;</span></span>
<span id="cb41-32" class="hljs-ln-code"><a href="#cb41-32"></a>plt.title(<span class="st">"Lasso Coefficient Path"</span>)<span class="op">;</span></span>
<span id="cb41-33" class="hljs-ln-code"><a href="#cb41-33"></a>plt.axis(<span class="st">"tight"</span>)<span class="op">;</span></span>
<span id="cb41-34" class="hljs-ln-code"><a href="#cb41-34"></a></span>
<span id="cb41-35" class="hljs-ln-code"><a href="#cb41-35"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-20-1.png" width="864"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2">

<p>Other penalties:</p>
<ul>
<li><span class="math inline">\(+ \lambda ||\boldsymbol{\beta}||_2\)</span>: ridge regression (Tikhonov regularisation, Tikhonov, A. N.; V. Y. Arsenin (1977). Solution of Ill-posed Problems.)</li>
<li><span class="math inline">\(+ \lambda_1 ||\boldsymbol{\beta}||_1 + \lambda_2 ||\boldsymbol{\beta}||_2\)</span>: elastic net (is equivalent to linear support vector machines)</li>
<li><span class="math inline">\(+ \lambda_1 ||\boldsymbol{w} \boldsymbol{\beta}||_1\)</span>: adaptive LASSO with some predefined weights from a prior (consistent) estimation, e.g., <span class="math inline">\(\boldsymbol{w} = (1/|\hat{\beta}_i|)_{i = 1, ...,p}\)</span> (adaptive LASSO estimates are nearly unbiased)</li>
<li>and many more</li>
</ul>
</section>
<section id="tikhonov-regularisation-ridge-regression" class="slide level2" data-number="3.3">
<h2><span class="header-section-number">3.3</span> Tikhonov Regularisation (Ridge Regression)</h2>
<p>Instead of an <span class="math inline">\(L_1\)</span> penalty, the Euclidean norm can be used in the Lagrangian minimisation <span class="math display">\[\begin{equation*}
    \hat{\boldsymbol{\beta}}_{\text{Ridge}}(\lambda) = \arg \min_{\boldsymbol{\beta} \in \mathbb{R}^{p}} \frac{1}{n} (\boldsymbol{Y} - \mathbf{X} \, \boldsymbol{\beta})^\prime (\boldsymbol{Y} - \mathbf{X} \, \boldsymbol{\beta}) + \lambda ||\beta||_2
\end{equation*}\]</span> with regularisation parameter <span class="math inline">\(\lambda \geq 0\)</span>.</p>
<div class="fragment">
<ul>
<li>Closed-form solution of the estimators <span class="math display">\[\begin{equation*}
  \hat{\boldsymbol{\beta}}_{\text{Ridge}}(\lambda) = (\mathbf{X}'\mathbf{X} + \lambda \mathbf{I})^{-1}\mathbf{X}'\boldsymbol{y}
\end{equation*}\]</span></li>
<li>If <span class="math inline">\(\lambda \rightarrow 0\)</span>, the estimator approaches the OLS solution</li>
<li>Can be used for high-dimensional settings (i.e., if <span class="math inline">\(\text{rank}(\mathbf{X}'\mathbf{X}) &gt; p\)</span>)</li>
</ul>
</div>
<div class="fragment">
<p>Compared to Lasso:</p>
<ul>
<li>Estimated parameters are only close to zero (not exactly zero) <span class="math inline">\(\leadsto\)</span> Ridge cannot be used to reduce the model complexity</li>
<li>Ridge-regression coefficients of correlated predictors are similar, while only one regressor has a large coefficient (and the others are (close to) zero) in a Lasso regression <span class="math inline">\(\leadsto\)</span> caution when Lasso is applied in settings of cross-correlated regressors</li>
<li>Ridge regression works better when many parameters are significant</li>
</ul>
</div>
</section>
<section id="elastic-net" class="slide level2" data-number="3.4">
<h2><span class="header-section-number">3.4</span> Elastic Net</h2>
<p>Convex combination of both penalties: <span class="math display">\[\begin{equation*}
    \hat{\boldsymbol{\beta}} = \arg \min_{\boldsymbol{\beta} \in \mathbb{R}^{p}} \frac{1}{n} (\boldsymbol{Y} - \mathbf{X} \, \boldsymbol{\beta})^\prime (\boldsymbol{Y} - \mathbf{X} \, \boldsymbol{\beta}) + \lambda_1 ||\beta||_1 + \lambda_2 ||\beta||_2
\end{equation*}\]</span> with regularisation parameter <span class="math inline">\(\lambda \geq 0\)</span>.</p>
<ul>
<li>Grid-search over two-dimensional space <span class="math inline">\((\lambda_1, \lambda_2)'\)</span></li>
<li>If <span class="math inline">\(\lambda_1 \rightarrow 0\)</span>, the <span class="math inline">\(\hat{\boldsymbol{\beta}}(\lambda_1, \lambda_2) \rightarrow \hat{\boldsymbol{\beta}}_{\text{Ridge}}(\lambda_2)\)</span></li>
<li>If <span class="math inline">\(\lambda_2 \rightarrow 0\)</span>, the <span class="math inline">\(\hat{\boldsymbol{\beta}}(\lambda_1, \lambda_2) \rightarrow \hat{\boldsymbol{\beta}}_{\text{Lasso}}(\lambda_1)\)</span></li>
<li>Elastic nets can be reduced to the linear support vector machine (i.e., SVM solvers can be applied)</li>
</ul>
<div class="fragment">
<div class="cell columns column-output-location" data-layout-align="center">
<div class="column">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb42-2"><a href="#cb42-2"></a></span>
<span id="cb42-3"><a href="#cb42-3"></a><span class="co"># Load the sample data</span></span>
<span id="cb42-4"><a href="#cb42-4"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb42-5"><a href="#cb42-5"></a></span>
<span id="cb42-6"><a href="#cb42-6"></a><span class="co"># Convert the data to matrices</span></span>
<span id="cb42-7"><a href="#cb42-7"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb42-8"><a href="#cb42-8"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="dv">1</span>])</span>
<span id="cb42-9"><a href="#cb42-9"></a></span>
<span id="cb42-10"><a href="#cb42-10"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(X)</span>
<span id="cb42-11"><a href="#cb42-11"></a></span>
<span id="cb42-12"><a href="#cb42-12"></a><span class="co"># Fit the LASSO model</span></span>
<span id="cb42-13"><a href="#cb42-13"></a>fit <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, y, <span class="at">intercept =</span> <span class="cn">TRUE</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb42-14"><a href="#cb42-14"></a><span class="co"># alpha elastic net mixing parameter</span></span>
<span id="cb42-15"><a href="#cb42-15"></a></span>
<span id="cb42-16"><a href="#cb42-16"></a><span class="co"># Plot the lambda path</span></span>
<span id="cb42-17"><a href="#cb42-17"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-21-3.png" width="864"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="selection-of-the-penalty-parameter" class="slide level2" data-number="3.5">
<h2><span class="header-section-number">3.5</span> Selection of the Penalty Parameter</h2>
<p>All regularised estimation procedure require the choice of the degree of regularisation</p>
<ul>
<li>Choice of the penalty parameter, often denoted by <span class="math inline">\(\lambda\)</span></li>
<li>If <span class="math inline">\(\lambda = 0\)</span>, the models coincide with their unpenalised version</li>
<li>Degree of penalisation increases with an increasing value of <span class="math inline">\(\lambda\)</span> <span class="math inline">\(\leadsto\)</span> degree of shrinkage of the parameters towards the shrinkage target increases and the estimated parameters are more biased</li>
</ul>
<div class="fragment">
<p><strong>Bias-variance tradeoff</strong></p>
<p>Example: <span class="math inline">\(Y = f(x) + \varepsilon\)</span></p>
<ul>
<li>The goodness of fit results from the estimated residuals, i.e., <span class="math inline">\(\hat{\varepsilon} = y - \hat{f}(x)\)</span></li>
<li>Thus, <span class="math display">\[\begin{equation}
E((Y - \hat{f}(x))^2 ) = Var (\hat f) + \text{bias}^2
\end{equation}\]</span></li>
<li>Most machine learning methods start exactly at this point (i.e., improving prediction accuracies by reducing the variance of the estimators)</li>
<li>Regularised regressions (e.g., Lasso or ridge regression) lead to a bias in the estimation of the model, but at the same time the variance of the estimated models decreases.</li>
<li>MSE can be lowered, resulting in higher prediction accuracies</li>
</ul>
</div>
<div class="fragment">
<div class="callout callout-tip callout-captioned callout-style-simple">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Bias-variance tradeoff</strong></p>
</div>
<div class="callout-content">
<p>Variance will always be reduced at the costs of bias and vice versa.</p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>Bias: High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).</p>
<p>Variance: High variance may result from an algorithm modelling the random noise in the training data (overfitting).</p>
</div>
</section>
<section class="slide level2">

<p><strong>Goodness-of-fit based</strong> criteria for selecting <span class="math inline">\(\lambda\)</span>:</p>
<ul>
<li>There is mostly no closed-form solution to get the optimal penalty parameter <span class="math inline">\(\lambda^*\)</span> <span class="citation" data-cites="BoonstraEtAl2015">(<a href="#/references" role="doc-biblioref" onclick="">Boonstra, Mukherjee, and Taylor 2015</a>)</span></li>
<li>Grid-search algorithms</li>
<li>Out-of-sample prediction performance is assessed in a cross-valdiation study</li>
<li>For a sequence <span class="math inline">\(\lambda_0, \ldots, \lambda_K\)</span> (usually on a exponentially decaying grid), <span class="math inline">\(\lambda^*\)</span> is chosen such that the out-of-sample RMSE, or MAE is minimised</li>
<li>Note: this procedure is often computationally expensive</li>
</ul>
<div class="fragment">
<p>Valid cross-validation schemes must satisfy three properties <span class="citation" data-cites="JiangWang2017">(<a href="#/references" role="doc-biblioref" onclick="">Jiang and Wang 2017</a>)</span>:</p>
<ul>
<li>Randomness of partition</li>
<li>Mutual independence of test errors</li>
<li>Independence between training set and test set.</li>
</ul>
<p><strong>Note:</strong> this is particularly relevant for spatiotemporal data (see Motivation) and random cross-validation schemes are typically not applicable</p>
</div>
</section>
<section class="slide level2">

<div class="cell columns column-output-location" data-layout-align="center">
<div class="column">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb43-2"><a href="#cb43-2"></a></span>
<span id="cb43-3"><a href="#cb43-3"></a><span class="co"># Load the sample data</span></span>
<span id="cb43-4"><a href="#cb43-4"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb43-5"><a href="#cb43-5"></a></span>
<span id="cb43-6"><a href="#cb43-6"></a><span class="co"># Convert the data to matrices</span></span>
<span id="cb43-7"><a href="#cb43-7"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb43-8"><a href="#cb43-8"></a>y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(mtcars[, <span class="dv">1</span>])</span>
<span id="cb43-9"><a href="#cb43-9"></a></span>
<span id="cb43-10"><a href="#cb43-10"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(X)</span>
<span id="cb43-11"><a href="#cb43-11"></a></span>
<span id="cb43-12"><a href="#cb43-12"></a><span class="co"># Fit the LASSO model</span></span>
<span id="cb43-13"><a href="#cb43-13"></a>fit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, y, <span class="at">intercept =</span> <span class="cn">TRUE</span>, <span class="at">type.measure =</span> <span class="st">"mse"</span>)</span>
<span id="cb43-14"><a href="#cb43-14"></a></span>
<span id="cb43-15"><a href="#cb43-15"></a><span class="co"># Plot the lambda path</span></span>
<span id="cb43-16"><a href="#cb43-16"></a><span class="fu">plot</span>(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-22-1.png" width="864"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2">

<div class="cell columns column-output-location" data-layout-align="center">
<div class="column">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a><span class="co"># Load the required libraries</span></span>
<span id="cb44-2"><a href="#cb44-2"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LassoCV</span>
<span id="cb44-3"><a href="#cb44-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb44-4"><a href="#cb44-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-5"><a href="#cb44-5"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb44-6"><a href="#cb44-6"></a></span>
<span id="cb44-7"><a href="#cb44-7"></a><span class="co"># Load the sample data</span></span>
<span id="cb44-8"><a href="#cb44-8"></a>cars <span class="op">=</span> pd.read_csv(<span class="st">'sources/mtcars.csv'</span>, index_col <span class="op">=</span> <span class="dv">0</span>, header <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb44-9"><a href="#cb44-9"></a></span>
<span id="cb44-10"><a href="#cb44-10"></a>lambdas <span class="op">=</span> np.logspace(<span class="op">-</span><span class="fl">4.5</span>, <span class="fl">0.9</span>, <span class="dv">100</span>)</span>
<span id="cb44-11"><a href="#cb44-11"></a></span>
<span id="cb44-12"><a href="#cb44-12"></a><span class="co"># Split the data into features and target</span></span>
<span id="cb44-13"><a href="#cb44-13"></a>X <span class="op">=</span> cars.drop(<span class="st">'mpg'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb44-14"><a href="#cb44-14"></a>y <span class="op">=</span> cars[<span class="st">'mpg'</span>]</span>
<span id="cb44-15"><a href="#cb44-15"></a></span>
<span id="cb44-16"><a href="#cb44-16"></a><span class="co"># Standardize data</span></span>
<span id="cb44-17"><a href="#cb44-17"></a>X <span class="op">-=</span> X.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-18"><a href="#cb44-18"></a>X <span class="op">/=</span> X.std(axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb44-19"><a href="#cb44-19"></a></span>
<span id="cb44-20"><a href="#cb44-20"></a><span class="co"># Fit LASSO model with cross-validation and k = 10 folds</span></span>
<span id="cb44-21"><a href="#cb44-21"></a>model <span class="op">=</span> LassoCV(alphas <span class="op">=</span> lambdas, cv <span class="op">=</span> <span class="dv">10</span>).fit(X, y)<span class="op">;</span></span>
<span id="cb44-22"><a href="#cb44-22"></a></span>
<span id="cb44-23"><a href="#cb44-23"></a><span class="co"># Plot average MAE across the lambda sequence</span></span>
<span id="cb44-24"><a href="#cb44-24"></a>plt.semilogx(model.alphas_, model.mse_path_, <span class="st">":"</span>)<span class="op">;</span></span>
<span id="cb44-25"><a href="#cb44-25"></a>plt.semilogx(model.alphas_, model.mse_path_.mean(axis<span class="op">=</span><span class="dv">1</span>), <span class="st">'k'</span>,</span>
<span id="cb44-26"><a href="#cb44-26"></a>         label<span class="op">=</span><span class="vs">r'Average across the folds'</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)<span class="op">;</span></span>
<span id="cb44-27"><a href="#cb44-27"></a>plt.xlabel(<span class="vs">r'$\lambda$'</span>)<span class="op">;</span></span>
<span id="cb44-28"><a href="#cb44-28"></a>plt.ylabel(<span class="st">'Mean squared error'</span>)<span class="op">;</span></span>
<span id="cb44-29"><a href="#cb44-29"></a>plt.title(<span class="st">'Mean squared error on each fold: Lasso'</span>)<span class="op">;</span></span>
<span id="cb44-30"><a href="#cb44-30"></a>plt.axis(<span class="st">'tight'</span>)<span class="op">;</span></span>
<span id="cb44-31"><a href="#cb44-31"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-23-1.png" width="864"></p>
</figure>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="applications-in-spatiotemporal-statistics" class="title-slide slide level1 center" data-number="4">
<h1><span class="header-section-number">4</span> Applications in Spatiotemporal Statistics</h1>

</section>
<section id="covariate-selection" class="slide level2" data-number="4.1">
<h2><span class="header-section-number">4.1</span> Covariate Selection</h2>
<ul>
<li>Like for the linear regression example, the regularisation can be used for covariate selection <span class="citation" data-cites="Zhu10">(see, e.g., <a href="#/references" role="doc-biblioref" onclick="">J. Zhu, Huang, and Reyes 2010</a>)</span></li>
</ul>
<p>Caution:</p>
<ul>
<li>Often spatiotemporal variables are cross-correlated due to their spatial nature <span class="math inline">\(\leadsto\)</span> adaptive Lasso procedures</li>
<li>Cross validation schemes must account for the spatial/temporal dependence</li>
<li>Penalised maximum-likelihood estimators, GMM, 2-stage least squares, etc.</li>
</ul>
</section>
<section id="dimensionality-reduction-covariance-matrix" class="slide level2" data-number="4.2">
<h2><span class="header-section-number">4.2</span> Dimensionality Reduction Covariance Matrix</h2>
<ul>
<li>Big-<span class="math inline">\(N\)</span> Problem <span class="math inline">\(\leadsto\)</span> clever methods to reduce the dimensionality are needed to apply geostatistical models to large data data sets</li>
</ul>
<p>Methods to reduce the dimensionality of the <strong>covariance matrix</strong>:</p>
<ul>
<li>Sparse covariance matrix (i.e., covariance matrix resulting from <span class="math inline">\(C_\theta\)</span> contains many zeros)
<ul>
<li>covariance tapering <span class="citation" data-cites="furrer2006covariance">(<a href="#/references" role="doc-biblioref" onclick="">Furrer, Genton, and Nychka 2006</a>)</span></li>
<li>theoretical results on covariance tapering can be found in <span class="citation" data-cites="stein2013statistical">Stein (<a href="#/references" role="doc-biblioref" onclick="">2013</a>)</span></li>
<li>covariance tapering for likelihood-based estimation procedures <span class="citation" data-cites="kaufman2008covariance furrer2016asymptotic">(see <a href="#/references" role="doc-biblioref" onclick="">Kaufman, Schervish, and Nychka 2008</a>; <a href="#/references" role="doc-biblioref" onclick="">Furrer, Bachoc, and Du 2016</a>)</span></li>
</ul></li>
</ul>
<p>Regularised estimation procedures (with a shrinkage target of zero)</p>
<div class="fragment">
<p>We can typically find zeros if two observations across space/time are conditionally independent, but conditional independence is encoded in the <strong>precision matrix</strong> (i.e., inverse covariance matrix):</p>
<ul>
<li>Lasso procedure to induce zeros in the precision matrix <span class="citation" data-cites="krock2021nonstationary krock2021modeling">(see <a href="#/references" role="doc-biblioref" onclick="">Krock, Kleiber, and Becker 2021</a> for univariate processes; and <a href="#/references" role="doc-biblioref" onclick="">Krock et al. 2021</a> for multivariate processes)</span></li>
<li>Graphical Lasso</li>
</ul>
</div>
<div class="fragment">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a><span class="fu">library</span>(gstat)</span>
<span id="cb45-2"><a href="#cb45-2"></a><span class="fu">library</span>(glasso)</span>
<span id="cb45-3"><a href="#cb45-3"></a></span>
<span id="cb45-4"><a href="#cb45-4"></a><span class="fu">set.seed</span>(<span class="dv">5515</span>)</span>
<span id="cb45-5"><a href="#cb45-5"></a></span>
<span id="cb45-6"><a href="#cb45-6"></a><span class="co"># Simulation of geostatistical process</span></span>
<span id="cb45-7"><a href="#cb45-7"></a>xy <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb45-8"><a href="#cb45-8"></a><span class="fu">names</span>(xy) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"x"</span>,<span class="st">"y"</span>)</span>
<span id="cb45-9"><a href="#cb45-9"></a><span class="fu">gridded</span>(xy) <span class="ot">=</span> <span class="er">~</span>x<span class="sc">+</span>y</span>
<span id="cb45-10"><a href="#cb45-10"></a>g.dummy <span class="ot">&lt;-</span> <span class="fu">gstat</span>(<span class="at">formula =</span> z <span class="sc">~</span> <span class="dv">1</span>, <span class="at">dummy =</span> <span class="cn">TRUE</span>, <span class="at">beta =</span> <span class="dv">0</span>,  <span class="at">model =</span> <span class="fu">vgm</span>(<span class="dv">1</span>, <span class="st">"Exp"</span>, <span class="dv">15</span>), <span class="at">nmax =</span> <span class="dv">100</span>) <span class="co"># for speed -- 10 is too small!!</span></span>
<span id="cb45-11"><a href="#cb45-11"></a>yy <span class="ot">&lt;-</span> <span class="fu">predict</span>(g.dummy, xy, <span class="at">nsim =</span> <span class="dv">500</span>)</span>
<span id="cb45-12"><a href="#cb45-12"></a><span class="fu">spplot</span>(yy[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-24-3.png" width="864"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1"></a><span class="co"># graphical Lasso </span></span>
<span id="cb46-2"><a href="#cb46-2"></a>x <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">do.call</span>(cbind, <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>, <span class="cf">function</span>(x) yy[x]<span class="sc">@</span>data)))</span>
<span id="cb46-3"><a href="#cb46-3"></a>s <span class="ot">&lt;-</span> <span class="fu">var</span>(x)</span>
<span id="cb46-4"><a href="#cb46-4"></a></span>
<span id="cb46-5"><a href="#cb46-5"></a>lambda.seq <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">^</span><span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">to =</span> <span class="fl">0.5</span>, <span class="at">length =</span> <span class="dv">50</span>)</span>
<span id="cb46-6"><a href="#cb46-6"></a>a <span class="ot">&lt;-</span> <span class="fu">glassopath</span>(s, <span class="at">rholist =</span> lambda.seq)</span>
<span id="cb46-7"><a href="#cb46-7"></a></span>
<span id="cb46-8"><a href="#cb46-8"></a><span class="co"># Plot the share of zeros in the estimated precision matrix </span></span>
<span id="cb46-9"><a href="#cb46-9"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>) <span class="sc">+</span> <span class="fl">0.3</span>)  </span>
<span id="cb46-10"><a href="#cb46-10"></a><span class="fu">plot</span>(<span class="fu">log</span>(a<span class="sc">$</span>rholist), <span class="fu">apply</span>(a<span class="sc">$</span>wi, <span class="dv">3</span>, <span class="cf">function</span>(x) <span class="fu">mean</span>(x <span class="sc">==</span> <span class="dv">0</span>)), </span>
<span id="cb46-11"><a href="#cb46-11"></a>     <span class="at">type =</span> <span class="st">"b"</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb46-12"><a href="#cb46-12"></a>     <span class="at">xlab =</span> <span class="st">"Log Lambda"</span>, <span class="at">ylab =</span> <span class="st">"Sparsity degree (precision matrix)"</span>)</span>
<span id="cb46-13"><a href="#cb46-13"></a><span class="fu">par</span>(<span class="at">new =</span> <span class="cn">TRUE</span>)</span>
<span id="cb46-14"><a href="#cb46-14"></a><span class="fu">plot</span>(<span class="fu">log</span>(a<span class="sc">$</span>rholist), <span class="fu">apply</span>(a<span class="sc">$</span>w, <span class="dv">3</span>, <span class="cf">function</span>(x) <span class="fu">mean</span>(x <span class="sc">==</span> <span class="dv">0</span>)),</span>
<span id="cb46-15"><a href="#cb46-15"></a>      <span class="at">type =</span> <span class="st">"b"</span>, , <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">"darkblue"</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">xlab =</span> <span class="st">""</span>)</span>
<span id="cb46-16"><a href="#cb46-16"></a><span class="fu">axis</span>(<span class="at">side=</span><span class="dv">4</span>, <span class="at">at =</span> <span class="fu">pretty</span>(<span class="fu">range</span>(<span class="fu">apply</span>(a<span class="sc">$</span>w, <span class="dv">3</span>, <span class="cf">function</span>(x) <span class="fu">mean</span>(x <span class="sc">==</span> <span class="dv">0</span>)))), <span class="at">col.axis =</span> <span class="st">"darkblue"</span>)</span>
<span id="cb46-17"><a href="#cb46-17"></a><span class="fu">mtext</span>(<span class="st">"Sparsity degree (covariance matrix)"</span>, <span class="at">side =</span> <span class="dv">4</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">"darkblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="ShortCourse_files/figure-revealjs/unnamed-chunk-24-4.png" width="864"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section class="slide level2">

<p>Note: Covariance matrix is a positive definite matrix by definition (i.e., for valid choices <span class="math inline">\(C_\theta\)</span>, see <span class="citation" data-cites="Cressie11">Cressie and Wikle (<a href="#/references" role="doc-biblioref" onclick="">2011</a>)</span>)</p>
<p>Thus, the covariance matrix and its inverse can be decomposed as <span class="math display">\[\begin{equation}
\mathbf{\Sigma} = \mathbf{P}\mathbf{P}',
\end{equation}\]</span> e.g., via Cholesky decomposition, where the matrix <span class="math inline">\(\mathbf{P}\)</span> is called Cholesky factor.</p>
<ul>
<li><span class="citation" data-cites="stein2004approximating">Stein, Chi, and Welty (<a href="#/references" role="doc-biblioref" onclick="">2004</a>)</span> proposed to approximate the likelihood for large spatial data sets based on Vecchia approximations <span class="citation" data-cites="vecchia1988estimation">(<a href="#/references" role="doc-biblioref" onclick="">Vecchia 1988</a>)</span></li>
<li>sparse Cholesky factors have be considered first by <span class="citation" data-cites="schaefer2021sparse">Schfer, Katzfuss, and Owhadi (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span> for spatial models</li>
</ul>
<div class="fragment">
<p>Aim: reduce dimension of <span class="math inline">\(\mathbf{P}\)</span> (<span class="math inline">\(N \times r\)</span>-dimensional), such that <span class="math inline">\(r \ll N\)</span></p>
</div>
<div class="fragment">
<ul>
<li>Low-rank covariance matrices have been considered first by <span class="citation" data-cites="banerjee2008gaussian">Banerjee et al. (<a href="#/references" role="doc-biblioref" onclick="">2008</a>)</span>, <span class="citation" data-cites="cressie2008fixed">Cressie and Johannesson (<a href="#/references" role="doc-biblioref" onclick="">2008</a>)</span> (spatial fixed-rank kriging), and <span class="citation" data-cites="cressie2010fixed">Cressie, Shi, and Kang (<a href="#/references" role="doc-biblioref" onclick="">2010</a>)</span> (spatiotemporal fixed-rank filtering)</li>
</ul>
<p>Idea: low-rank approximations aim to represent a spatiotemporal process as a linear combination of local basis functions, which are weighted by uncorrelated random-effect coefficients</p>
<ul>
<li>Penalised estimation procedures to identify the lower rank of the covariance matrix <span class="citation" data-cites="chang2010semiparametric">(<a href="#/references" role="doc-biblioref" onclick="">Chang, Hsu, and Huang 2010</a>)</span></li>
<li>Select suitable local basis functions via penalised estimation procedures (with zero penalty target)</li>
<li><span class="citation" data-cites="hsu2012group">Hsu, Chang, and Huang (<a href="#/references" role="doc-biblioref" onclick="">2012</a>)</span> suggested a penalised procedures to choose these local basis functions for spatiotemporal processes</li>
</ul>
<p>The same idea could also be employed for sparse inverse Cholesky factors <span class="citation" data-cites="kang2021correlation">(see <a href="#/references" role="doc-biblioref" onclick="">Kang and Katzfuss 2021</a>)</span></p>
</div>
</section>
<section class="slide level2">

<p><strong>Bayesian penalised regression</strong></p>
<div class="fragment">
<p>Fully Bayesian approach:</p>
<ul>
<li>Penalty parameter <span class="math inline">\(\lambda\)</span> is treated like a unknown variable, for which a prior distribution is specified <span class="citation" data-cites="van2019shrinkage">(<a href="#/references" role="doc-biblioref" onclick="">Van Erp, Oberski, and Mulder 2019</a>)</span></li>
<li>Often vague prior <span class="math inline">\(p(\lambda)\)</span>, e.g., <span class="math inline">\(\lambda \sim \text{half-Cauchy}(0, 1)\)</span></li>
<li>Shrinkage priors for the parameters (i.e., zero-mean distributions lead to a shrinkage target of zero), e.g.,
<ul>
<li>Ridge prior (regression parameters): <span class="math inline">\(\beta_j | \lambda, \sigma \sim N(0, \sigma^2 / \lambda)\)</span> <span class="citation" data-cites="hsiang1975bayesian">(<a href="#/references" role="doc-biblioref" onclick="">Hsiang 1975</a>)</span></li>
<li>Lasso prior: <span class="math inline">\(\beta_j | \lambda, \sigma \sim \text{Laplace}(0, \sigma /\lambda)\)</span> <span class="citation" data-cites="park2008bayesian">(<a href="#/references" role="doc-biblioref" onclick="">Park and Casella 2008</a>)</span></li>
<li>Elastic net: mixture distribution of the ridge and Lasso prior</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<p>Two-step procedures:</p>
<ul>
<li>Penalty parameter <span class="math inline">\(\lambda\)</span> is estimated in a first step and then used in the Bayesian framework (treated as a known variable)</li>
<li>Choose <span class="math inline">\(\lambda^*\)</span> as</li>
</ul>
<p><span class="math display">\[\begin{equation}
  \lambda^* = \arg\max_\lambda p(Y = y | \lambda)
\end{equation}\]</span></p>
<ul>
<li>Bayesian estimate of <span class="math inline">\(\lambda^*\)</span> is mode of the marginal posterior <span class="math inline">\(p(\lambda | y)\)</span></li>
<li>No prior specification for <span class="math inline">\(\lambda\)</span> needed (i.e., non-informative prior)</li>
<li>Sensitivity analysis is needed</li>
</ul>
</div>
<div class="fragment">
<p>CV-based selection of the penalty parameter:</p>
<ul>
<li><span class="math inline">\(\lambda^*\)</span> is selected such that the likelihood in the validation set is maximised</li>
<li>Grid-search algorithm</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Integrated nested Laplace approximation (INLA) <span class="citation" data-cites="rue2017bayesian">(see <a href="#/references" role="doc-biblioref" onclick="">Rue et al. 2017</a> for a review)</span></li>
<li>High-dimensional prior and posterior covariance matrices <span class="citation" data-cites="furrer2007estimation">(<a href="#/references" role="doc-biblioref" onclick="">Furrer and Bengtsson 2007</a>)</span></li>
</ul>
</div>
</section>
<section id="estimation-of-spatial-weight-matrix" class="slide level2" data-number="4.3">
<h2><span class="header-section-number">4.3</span> Estimation of Spatial Weight Matrix</h2>
<p>Penalised estimation procedures (penalised maximum likelihood) can be used for selection of the covariates in spatial autoregressive models <span class="citation" data-cites="liu2018penalized">(<a href="#/references" role="doc-biblioref" onclick="">Liu, Chen, and Cheng 2018</a>)</span>; see also <span class="citation" data-cites="gonella2022facing">Gonella, Bourel, and Bel (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span></p>
<div class="fragment">
<p>Precision matrix of spatial autoregressive models is given by <span class="math display">\[\begin{equation}
    (\mathbf{I} - \rho \mathbf{W})' \mathbf{\Sigma}_{\varepsilon}^{-1} (\mathbf{I} - \rho \mathbf{W})
\end{equation}\]</span> showing the relation to the above-mentioned Cholesky decomposition of geostatistical models.</p>
<p>That is, the spatial weight matrix <span class="math inline">\(\mathbf{W}\)</span> implies a certain (geographical) structure of the Cholesky factors. <span class="citation" data-cites="zhu2009estimating">Z. Zhu and Liu (<a href="#/references" role="doc-biblioref" onclick="">2009</a>)</span> proposed a Lasso procedure to estimate the precision matrix exploiting the fact that geographically distant observation are likely to be conditionally independent (i.e., the precision matrix is a sparse matrix).</p>
</div>
<div class="fragment">
<p>Spatial interactions can be modelled using a series of different weight structures, e.g., <span class="math inline">\(\sum_{i = 1}^{k} \rho_i \mathbf{W}_i\)</span> with <span class="math inline">\(k\)</span> different weight matrices <span class="math inline">\(\mathbf{W}_i\)</span> (e.g., directional matrices, see <span class="citation" data-cites="merk2021directional">Merk and Otto (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span>)</p>
<p>Idea:</p>
<ul>
<li>Consider a series of alternative weight matrices <span class="math inline">\(\mathbf{W}_1, \ldots, \mathbf{W}_k\)</span></li>
<li>Select the true weight matrix <span class="math inline">\(\mathbf{W}\)</span> by a penalised estimation procedure (e.g., penalised maximum likelihood)</li>
<li>Penalty on the <span class="math inline">\(\rho\)</span> parameters with zero target</li>
<li>Boosting procedures <span class="citation" data-cites="kostov2010model kostov2013spatial">(<a href="#/references" role="doc-biblioref" onclick="">Philip Kostov 2010</a>; <a href="#/references" role="doc-biblioref" onclick="">Phillip Kostov 2013</a>)</span>, Lasso <span class="citation" data-cites="lam2020estimation">(<a href="#/references" role="doc-biblioref" onclick="">Lam and Souza 2020</a>)</span></li>
</ul>
</div>
<div class="fragment">
<p>Instead of linear parametric form <span class="math inline">\(\mathbf{B} = \rho \mathbf{W}\)</span>, consider the entire matrix <span class="math inline">\(\mathbf{B}\)</span> as unknown parameter of the model. <strong>But:</strong></p>
<ul>
<li><span class="math inline">\((\mathbf{I} - \mathbf{B})^{-1}\)</span> must exist to have a well-defined model <span class="math inline">\(\leadsto\)</span> constrained estimation procedures</li>
<li><span class="math inline">\(\mathbf{B}\)</span> has <span class="math inline">\(n(n-1)\)</span> free parameters when we have <span class="math inline">\(n\)</span> locations <span class="math inline">\(\leadsto\)</span> (often) high-dimensional set up with more parameters than observations</li>
<li><span class="math inline">\(\mathbf{B}\)</span> is typically a sparse matrix <span class="math inline">\(\leadsto\)</span> zero shrinkage target</li>
<li>Identification of each single weight <span class="citation" data-cites="manski1993identification gibbons2012mostly">(see <a href="#/references" role="doc-biblioref" onclick="">Manski 1993</a>; and <a href="#/references" role="doc-biblioref" onclick="">Gibbons and Overman 2012</a> for a critical review of spatial econometric procedures)</span>
<ul>
<li>if one weight between region A and B, say <span class="math inline">\(w_{ab}\)</span>, is misspecified, this can be compensated via further linkages through other locations, e.g., via <span class="math inline">\(w_{ac}\)</span> and <span class="math inline">\(w_{cb}\)</span>, and still lead to the same spatial covariance matrix</li>
<li>two-sided but directed links between A and B (i.e., <span class="math inline">\(w_{ab}\)</span> and <span class="math inline">\(w_{ba}\)</span>)</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<p>Spatiotemporal models:</p>
<p><span class="citation" data-cites="bhattacharjee2013estimation">Bhattacharjee and Jensen-Butler (<a href="#/references" role="doc-biblioref" onclick="">2013</a>)</span> first proposed the idea of estimating the full matrix <span class="math inline">\(\mathbf{B}\)</span> with further structural constraints for identification (i.e., symmetry). <span class="citation" data-cites="ahrens2015two">Ahrens and Bhattacharjee (<a href="#/references" role="doc-biblioref" onclick="">2015</a>)</span> proposed a two-step LASSO procedure; <span class="citation" data-cites="lam2020estimation">Lam and Souza (<a href="#/references" role="doc-biblioref" onclick="">2020</a>)</span> suggested a regularised estimation for spatial lag models.</p>
<p>Constrained two-step Lasso procedure with an unknown number of structural breaks in the mean <span class="citation" data-cites="otto2022estimation">(<a href="#/references" role="doc-biblioref" onclick="">Otto and Steinert 2022</a>)</span>.</p>
<ul>
<li>Selection criterion based on the similarity between the model and sample cross-correlation</li>
<li>Remember: estimated parameters are not necessarily uniquely identifiable, but the fitted observations are unique <span class="math inline">\(\leadsto\)</span> single weights should be interpreted with caution</li>
</ul>

<!--


::: {.cell layout-align="center"}

```{.r .cell-code  code-fold="true"}
##############################################################
#
# Packages and functions needed
#
##############################################################


RNGversion("3.6.0") ## define the relevant r-version and seed to achieve same results
set.seed(1234)

## load libraries for estimation and plotting

library("glmnet")
library("doParallel")
library("foreach")
library("spdep")
library("Matrix")
library("ROI")
library("ROI.plugin.qpoases")
library("plotrix")
library("terra")


## raw data

ts <- terra::rast("sources/NDWI_neustadtermoor.tif")
shape <- terra::vect("sources/Probeflaeche_Neustaedter_Moor/Probeflaeche_Neustaedter_Moor.shp")

ts <- ts / 10000
ts <- terra::crop(ts, shape)
ts <- terra::mask(ts, shape)

# plot some scenes
plot(ts[[1:3]])

datum <- substr(names(ts),nchar(names(ts))-12,
                nchar(names(ts))-5)
datum <- as.Date(datum,format="%Y%m%d")

T <- dim(ts)[3]
regions <- 1:prod(dim(ts)[1:2])

ndvimat    <- as.matrix(ts)
ndvimat    <- ndvimat[, order(datum)]
dat_sorted <- datum[order(datum)]

remove_i <- which(apply(is.na(ndvimat), 1, mean) > 0.5 | apply(ndvimat == 0, 1, mean) > 0.5)
regions  <- regions[-remove_i]
ndvimat  <- ndvimat[-remove_i, ] 

n <- dim(ndvimat)[1]

plot(dat_sorted, ndvimat[1,], type = "l")

row.names(ndvimat) <- regions

ndvimat[ndvimat == 0] <- mean(ndvimat[ndvimat != 0])
ndvimat[ndvimat > quantile(ndvimat, 0.98) | ndvimat < quantile(ndvimat, 0.02) ] <- mean(ndvimat[ndvimat != 0])

ndvimat <- (ndvimat - mean(ndvimat)) / sd(ndvimat)

ndvimat <- t(ndvimat)
save.colnames <- colnames(ndvimat)

##############################################################
#
# Setup parameters and data
#
##############################################################


solver_func_difflam <- function(X, y, lambda, Aeq, beq, A, b){ ## the ROI solver function which allows the users to specify different lambdas for each regressor; it also enables equality and inqueality constraints
  m1 <- dim(Aeq)[1]
  m2 <- dim(A)[1]
  
  p <- ncol(X)
  
  H <- t(X) %*% X
  H <- rbind(cbind(H, -H), cbind(-H, H)) ## setup the model matrix; be aware that we estimate beta and -beta to use the well known "trick" to make optimization of abs(beta) computationally feasible 
  
  # constraints
  Amatrix <- rbind(cbind(Aeq, -Aeq), cbind(A, -A)) ## combine the equality matrix of Aeq*beta=beq and the inequality conditions A*beta=b, again consider the trick for optimizing abs(beta)
  bvector <- c(beq, b)
  
  # linear coefficient
  add_v <- -t(X)%*%y ## following standard regression
  
  if(length(lambda)==1){ ## make code more felxible for one paramater regression - which is not needed in our case tho
    lambda <- rep(lambda,2*p)
  }else{
    lambda <- c(lambda,lambda)
  }
  
  f <- as.matrix(lambda*matrix(c(rep(1,p),rep(1,p)),2*p,1)+rbind(add_v,-add_v)) ## add the l1 constraint parameter lambda utilizing the before mentioned trick 
  
  x <- OP(Q_objective(as.matrix(H), L = t(f)), L_constraint( L= as.matrix(Amatrix), dir = c(rep("==", as.numeric(m1)), rep("<=", as.numeric(m2))), rhs = as.numeric(bvector))) ## ROI optimizer model setup
  
  #optimizer
  opt <- ROI_solve(x, solver="qpoases") ## please make sure qpoases plugin is loaded
  opt_sol <-  opt$message$primal_solution
  
  beta_mat <- matrix(opt_sol[1:p] - opt_sol[(p+1):length(opt_sol)], p, 1)
  
  
  return(beta_mat)
}


alpha <- 1
gamma.ada <- 1

lambda.seq.1stpass <- c(2^seq(5, -5, length = 99), 0)
lambda.seq.2ndpass <- c(2^seq(-5, -22, length = 50), 0)

nfolds.cv <- 20
n_cv <- 2 

## data

ndvi <- ndvimat
colnames(ndvi) <- save.colnames

Y.mat <- ndvi - mean(ndvi)
Y <- as.numeric(ndvi)
CP.prep <- matrix(1, T, T)
CP.prep[upper.tri(CP.prep)] <- 0

##############################################################
#
# 1st stage - candidate change points
#
##############################################################

## first stage, get the possible CP ##

means.est <- c()

for (i.n in 1:n) {
  ## ## 12 th n is very unstable due to lots of 0
  
  ridge.CP <- cv.glmnet(CP.prep, Y[1:T + T * (i.n - 1)], alpha = 0, 
                        intercept = FALSE, lambda = lambda.seq.1stpass, nfolds = nfolds.cv, 
                        parallel = TRUE)
  pos <- which(round(ridge.CP$lambda.1se, 5) == round(lambda.seq.1stpass, 
                                                      5))
  beta.CP <- ridge.CP$glmnet.fit$beta[, pos] + 1e-06  ## to adj pars which are 0
  
  
  
  weights <- 1/abs(beta.CP)^gamma.ada
  
  
  lasso.CP <- cv.glmnet(CP.prep, Y[1:T + T * (i.n - 1)], penalty.factor = weights, 
                        alpha = alpha, intercept = FALSE, lambda = lambda.seq.1stpass, 
                        nfolds = nfolds.cv, parallel = TRUE)
  # pos <- which(round(lasso.CP$lambda.1se, 5) == round(lambda.seq.1stpass, 5))
  pos <- which(round(lasso.CP$lambda.min, 5) == round(lambda.seq.1stpass, 5))
  beta.CP <- lasso.CP$glmnet.fit$beta[, pos]
  beta.CP[1] <- beta.CP[2]  ## first beta problem
  beta.CP[2] <- 0
  
  means.est[1:T + T * (i.n - 1)] <- CP.prep %*% beta.CP
  
}

Y.mat.new <- Y.mat
Y.new <- as.numeric(Y.mat.new)
X.new <- Matrix(0, length(Y.new), n * n)
X.CP_mean <- Matrix(0, length(Y.new), T * n)

for (i in 1:n) {
  X.new[(1:T) + T * (i - 1), (1:n) + n * (i - 1)] <- Y.mat.new  ## copy the mat alongside the 'diagonal'
  X.CP_mean[(1:T) + T * (i - 1), (1:T) + T * (i - 1)] <- CP.prep
}

ind_remove <- seq(1, n^2, n) + (0:(n - 1))

X.new <- X.new[, -ind_remove]  ## to avoid self dependencies

sel_CP <- which(diff(means.est) != 0) + 1
adj_CP <- sel_CP[-sort(c(which(((sel_CP)/T)%%1 == 0), which(((sel_CP)/T)%%1 > 
                                                              0.95)))]  ## adjust so no change point is allowed at the last e.g. 5 percent of the data

X.CP <- X.CP_mean[, adj_CP]  ## only get those where we detected a CP

X.full <- cbind(X.CP, X.new)


##############################################################
#
# 2nd stage - full model
#
##############################################################

## estimate adaptive lasso with the possible CP and the weight matrix

## Cross validation study to get lambda - not using glmnet cv prebuild function due to specific spatial structure

cp_counts <- as.numeric(table(Reduce(c,apply(apply(apply(X.CP,2,diff),2,"==",-1),2,which)))) ## extract CP to restore for each station: currently we have all cp for all n stacked together, but as the roi will use great CPU time when n and p is small we estimate every n separatedly (without loss of generality) and therefore need to split up the cp for every n again

beta_mat <- matrix(0,ncol(X.full),length(lambda.seq.2ndpass)) ## fill with zero, so later cp which we detect and remove with cp are set to zero

rmse_mat <- matrix(,length(lambda.seq.2ndpass),n_cv)
cor_err_mat <- matrix(,length(lambda.seq.2ndpass),n_cv)

w_est_list <- list() ## to save the weight mat for each n and later reconstruct by using the average
a_est_list <- list() ## same as above for a

for(i.cv in 1:n_cv){
  
  if(i.cv==1){
    leftout_rand <- (1:T)[which((1:T)%%2==1)] ## use odd numbers, assuming a cp must last for at least 2 obs
  }else{
    leftout_rand <- (1:T)[which((1:T)%%2==0)] ## use even numbers
  }
  
  rmse_vec <- c()
  cor_err <- c()
  
  w_est <- list()
  a_est <- list()
  
  eps_new <- matrix(rnorm(T*n,0,1),T,n) ## this eps will be used to be passed through our resulting estimating for Y in order to get infos on the cov matrix
  
  for(i.pass in 1:length(lambda.seq.2ndpass)){ ## for every lambda
    
    
    ind_leftout <- c()
    
    beta_roi <- rep(0,ncol(X.full))
    
    for(i.split in 1:n){ ## for every station
      if(i.split==1){
        ind_cp_single <- 1:tail(cumsum(cp_counts[1:i.split]), 1) ## get index for cp
      }else if(i.split!=n){
        ind_cp_single <- (tail(cumsum(cp_counts[1:(i.split-1)]),1)+1):tail(cumsum(cp_counts[1:i.split]), 1)
      }else{
        ind_cp_single <- (tail(cumsum(cp_counts[1:(i.split-1)]),1)+1):ncol(X.CP)
      }
      
      ind_w_single <- (ncol(X.CP)+1):(ncol(X.CP)+(n-1))+(i.split-1)*(n-1) ## get the index for the w
      
      full_col <- c(ind_cp_single,ind_w_single) ## combine the index of the w and possible cp for the current station i.n
      
      ind_full_roi <- (1:T)+T*(i.split-1) ## contains the corresponding observations t, as we have to understand that Y was a stacked vector before, now we nee to figure out which t correspond to exactly the current i.n
      
      ind_leftout <- ind_full_roi[leftout_rand] ## split in-sample and out-of-sample
      ind_full_roi <- ind_full_roi[-leftout_rand]
      
      
      X.full.train <- as.matrix(X.full[ind_full_roi, full_col])
      Y.new.train <- as.matrix(Y.new[ind_full_roi])
      
      if(length(ind_cp_single) == 1){
        get.zero <- which(X.full.train[, 1:length(ind_cp_single)] == 0) ## in the case we will have some 0 value rows due to the cv split
      } else {
        get.zero <- which(colMeans(X.full.train[, 1:length(ind_cp_single)]) == 0) ## in the case we will have some 0 value rows due to the cv split
      }
      
      
      if (length(get.zero) != 0) { ## if we actually have some x.cp which only have ones in the test set and not in the train set, we artificially set one t to 1, to avoid solver problems
        X.full.train[nrow(X.full.train), get.zero] <- 1
        n.CP <- ncol(X.CP) - length(get.zero)
        get.zero <- c()
      }
      
      n.CP <- ncol(X.CP)
      
      ## Setup the solver constraint, i.e. no equality constraints, all beta must be smaller 1 but greater 0 and the sum is always smaller than 1
      
      Aeq <- matrix(,0,ncol(X.full.train))
      beq <- rep(0,0)
      A <- rbind(c(rep(0,length(ind_cp_single)-length(get.zero)),rep(1,ncol(X.full.train)-length(ind_cp_single)+length(get.zero))),diag(ncol(X.full.train))[(length(ind_cp_single)-length(get.zero)+1):ncol(X.full.train),],-diag(ncol(X.full.train))[(length(ind_cp_single)-length(get.zero)+1):ncol(X.full.train),])
      b <- matrix(c(1,rep(1,length(ind_w_single)),rep(0,length(ind_w_single))),1,nrow(A))
      
      lam_adj <- c(rep(0,length(ind_cp_single)),rep(nrow(X.full.train)*lambda.seq.2ndpass[i.pass],n-1))
      
      res <- solver_func_difflam(X.full.train,Y.new.train,lam_adj,Aeq,beq,A,b)
      
      beta_roi[ind_w_single] <- as.numeric(tail(res,n-1)) ## we save the beta which corresponded to that i.n to later have a full vec of beta for all n stations
      
      if(length(get.zero)==0){ ## again adjustment to to illful cv break
        beta_roi[ind_cp_single] <- res[1:length(ind_cp_single)]
      }else{
        beta_roi[ind_cp_single[-get.zero]] <- res[1:(length(ind_cp_single)-length(get.zero))]
      }
      
    } ## end of loop over all n stations
    
    
    beta.full <- beta_roi
    
    beta_final <- beta.full[-(1:ncol(X.CP))]  ## delete the betas which correspond to CP
    beta.CP <- beta.full[1:ncol(X.CP)] ## get the betas which correspond to CP
    W_est_lasso <- matrix(, n, n)
    diag(W_est_lasso) <- 0 ##to avoid self dependency
    
    est.mean <- rep(0, T * n)
    est.mean[adj_CP] <- beta.CP  ## provide betas for corresponding CP
    est.mean <- matrix(est.mean, T, n)  ## allocate so that we do not mix betas of different n
    
    est.mean.final <- apply(est.mean, 2, cumsum)
    
    for (i in 1:n) {
      W_est_lasso[i, which(is.na(W_est_lasso[i, ]))] <- beta_final[1:(n - 
                                                                        1) + (i - 1) * (n - 1)]
    }
    
    new_est <- t(solve(diag(n) - W_est_lasso)%*%t(eps_new)) ## important: we flush the new simulated errors through our estimated w to receive a new sample
    new_real <- Y.mat - t(solve(diag(n) - W_est_lasso)%*%t(est.mean.final)) ## important: we demean the true series Y.mat; if and only if a and w are estimated perfectly, the cor of new_est and new_real must be identical!
    
    cor_est <- cor(new_est)
    cor_real <- cor(new_real)
    
    rmse_vec[i.pass] <- mean((Y.new[ind_leftout] - X.full[ind_leftout,] %*% beta.full)^2)
    cor_err[i.pass] <- mean(abs(cor_est-cor_real))
    
    w_est[[i.pass]] <- W_est_lasso 
    a_est[[i.pass]] <- est.mean.final
  } ## end loop over the lambdas
  
  rmse_mat[,i.cv] <- rmse_vec
  cor_err_mat[,i.cv] <- cor_err
  
  a_est_list[[i.cv]] <- a_est
  w_est_list[[i.cv]] <- w_est
  
  
} ## end loop over the cv iterations

cor_means <- apply(cor_err_mat,1,mean) ## get the means of the error in the cor

plot(cor_means)

decision <- which.min(cor_means) ## which lambda had the least cor err

pos <- decision

## reconstruct the estimates for w and a by averaging

w_test <- list()

for(j in 1:length(lambda.seq.2ndpass)){
  w_full <- matrix(0,n,n)
  for(i in 1:length(w_est_list)){
    w_full <- w_full + w_est_list[[i]][[j]]
  }
  w_test[[j]] <- w_full/length(w_est_list) ## mean
}

a_test <- list()

for(j in 1:length(lambda.seq.2ndpass)){
  a_full <- matrix(0,T,n)
  for(i in 1:length(a_est_list)){
    a_full <- a_full + a_est_list[[i]][[j]]
  }
  a_test[[j]] <- a_full/length(a_est_list) ## mean
}

W_est_lasso <- w_test[[decision]] ## take the best model according to the mean cor error
est.mean.final <- a_test[[decision]]

overall_mean <- t(solve(diag(n) - W_est_lasso) %*% t(est.mean.final))

save.image("final_result.Rdata")
```
:::

::: {.cell layout-align="center"}

```{.r .cell-code}
library("terra")
load("sources/final_result.Rdata")

ts    <- terra::rast("sources/NDWI_neustadtermoor.tif")
shape <- terra::vect("sources/Probeflaeche_Neustaedter_Moor/Probeflaeche_Neustaedter_Moor.shp")

ts <- ts / 10000
ts <- terra::crop(ts, shape)
ts <- terra::mask(ts, shape)
regions_full <- 1:prod(dim(ts)[1:2])

decision <- which.min(cor_means) ## which lambda had the least cor err

pos <- decision

## reconstruct the estimates for w and a by averaging

w_test <- list()

for(j in 1:length(lambda.seq.2ndpass)){
  w_full <- matrix(0,n,n)
  for(i in 1:length(w_est_list)){
    w_full <- w_full + w_est_list[[i]][[j]]
  }
  w_test[[j]] <- w_full/length(w_est_list) ## mean
}

a_test <- list()

for(j in 1:length(lambda.seq.2ndpass)){
  a_full <- matrix(0,T,n)
  for(i in 1:length(a_est_list)){
    a_full <- a_full + a_est_list[[i]][[j]]
  }
  a_test[[j]] <- a_full/length(a_est_list) ## mean
}

W_est_lasso <- w_test[[decision]] ## take the best model according to the mean cor error
est.mean.final <- a_test[[decision]]

overall_mean <- t(solve(diag(n) - W_est_lasso) %*% t(est.mean.final))
```
:::



-->
<!--


::: {.cell layout-align="center"}

```{.r .cell-code  code-fold="true"}
solver_func_difflam <- function(X, y, lambda, Aeq, beq, A, b){ ## the ROI solver function which allows the users to specify different lambdas for each regressor; it also enables equality and inqueality constraints
  m1 <- dim(Aeq)[1]
  m2 <- dim(A)[1]
  
  p <- ncol(X)
  
  H <- t(X) %*% X
  H <- rbind(cbind(H, -H), cbind(-H, H)) ## setup the model matrix; be aware that we estimate beta and -beta to use the well known "trick" to make optimization of abs(beta) computationally feasible 
  
  # constraints
  Amatrix <- rbind(cbind(Aeq, -Aeq), cbind(A, -A)) ## combine the equality matrix of Aeq*beta=beq and the inequality conditions A*beta=b, again consider the trick for optimizing abs(beta)
  bvector <- c(beq, b)
  
  # linear coefficient
  add_v <- -t(X)%*%y ## following standard regression
  
  if(length(lambda)==1){ ## make code more felxible for one paramater regression - which is not needed in our case tho
    lambda <- rep(lambda,2*p)
  }else{
    lambda <- c(lambda,lambda)
  }
  
  f <- lambda*matrix(c(rep(1,p),rep(1,p)),2*p,1) + rbind(add_v, -add_v) ## add the l1 constraint parameter lambda utilizing the before mentioned trick 
  
  x <- OP(Q_objective(as.matrix(H), L = t(as.matrix(f))), L_constraint(L=Amatrix, dir=c(rep("==", m1), rep("<=", m2)), rhs=bvector)) ## ROI optimizer model setup
  
  #optimizer
  opt <- ROI_solve(x, solver="qpoases") ## please make sure qpoases plugin is loaded
  opt_sol <-  opt$message$primal_solution
  
  beta_mat <- matrix(opt_sol[1:p] - opt_sol[(p+1):length(opt_sol)], p, 1)
  
  
  return(beta_mat)
}
```
:::

::: {.cell layout-align="center"}

```{.r .cell-code}
library("ROI") 
library("ROI.plugin.qpoases")
library("igraph")

load("sources/DataCREA.rda")

alpha <- 1
gamma.ada <- 1

lambda.seq.2ndpass <- c(2^seq(-2, 2, length = 19), 0)

n_cv <- 2 

# model_formula <- MeanHJ_Manure_Processed_Tot ~  BDN_Anim + Land_Agric + ValAgr_High + DEM_avg
data_panel <- t(matrix(Data_full$MeanHJ_Manure_Processed_Tot, ncol = length(unique(Data_full$Year)), nrow = length(unique(Data_full$Agrarian_SubRegion))))

k <- 4
data_panel_X <- array(, dim = c(dim(data_panel)[1], dim(data_panel)[2], k))
data_panel_X[,,1] <- t(matrix(Data_full$BDN_Anim, ncol = length(unique(Data_full$Year)), nrow = length(unique(Data_full$Agrarian_SubRegion))))
data_panel_X[,,2] <- t(matrix(Data_full$Land_Agric, ncol = length(unique(Data_full$Year)), nrow = length(unique(Data_full$Agrarian_SubRegion))))
data_panel_X[,,3] <- t(matrix(Data_full$ValAgr_High, ncol = length(unique(Data_full$Year)), nrow = length(unique(Data_full$Agrarian_SubRegion))))
data_panel_X[,,4] <- t(matrix(Data_full$DEM_avg, ncol = length(unique(Data_full$Year)), nrow = length(unique(Data_full$Agrarian_SubRegion))))


T     <- dim(data_panel)[1]
n     <- dim(data_panel)[2]
Y.mat <- data_panel
Y     <- as.numeric(Y.mat)

Y.mat.new <- Y.mat
Y.new <- as.numeric(Y.mat.new)

parallel <- FALSE

maxlag <- 2


X.W       <- Matrix(0, length(Y.new), n * n, sparse = TRUE) # spatial dependence
X.temp_ar <- Matrix(0, length(Y.new), maxlag, sparse = TRUE) # temporal autoregressive
X.regr    <- Matrix(0, length(Y.new), k, sparse = TRUE) # regressive effects
time_remove <- NULL

for (i in 1:n) {
  X.W[(1:T) + T * (i - 1), (1:n) + n * (i - 1)] <- Y.mat.new  ## copy the mat alongside the 'diagonal'
  for(j in 1:maxlag){
    X.temp_ar[(1:T) + T * (i - 1), j] <- c(rep(NA, j), Y.mat[-c((T - j + 1):T), i])
    cat(round(j/maxlag,4)*100, "\t")
  }
  time_remove <- append(time_remove, ((1:T) + T * (i - 1))[1:maxlag])
}

for(regr in 1:k){
  X.regr[,regr] <- as.numeric(data_panel_X[,,regr])
}

ind_remove <- seq(1, n^2, n) + (0:(n - 1))

X.W <- X.W[-time_remove, -ind_remove]  ## to avoid self dependencies
X.temp_ar <- X.temp_ar[-time_remove, ]
X.regr <- X.regr[-time_remove, ]

Y.mat <- Y.mat[-c(1:maxlag),]
Y <- as.numeric(Y.mat)

Y.mat.new <- Y.mat
Y.new <- as.numeric(Y.mat.new)


X.full <- cbind(X.temp_ar, X.W, X.regr)


## estimate adaptive lasso with the possible CP and the weight matrix

## Cross validation study to get lambda - not using glmnet cv prebuild function due to specific spatial structure

beta_mat <- matrix(0,ncol(X.full),length(lambda.seq.2ndpass)) ## fill with zero, so later cp which we detect and remove with cp are set to zero

rmse_mat <- matrix(,length(lambda.seq.2ndpass),n_cv)
cor_err_mat <- matrix(,length(lambda.seq.2ndpass),n_cv)

w_est_list      <- list() ## to save the weight mat for each n and later reconstruct by using the average
a_est_list      <- list() ## same as above for a
beta_coeff      <- list() ## same as above for beta
ar_coeff_list   <- list() ## ar coefficients (in contrast, a_est_list is the estimated mean level)

for(i.cv in 1:n_cv){
  
  if(i.cv==1){
    leftout_rand <- (1:(T-maxlag))[which((1:(T-maxlag))%%2==1)] ## use odd numbers, assuming a cp must last for at least 2 obs
  }else{
    leftout_rand <- (1:(T-maxlag))[which((1:(T-maxlag))%%2==0)] ## use even numbers
  }
  
  rmse_vec <- c()
  cor_err <- c()
  
  w_est <- list()
  a_est <- list()
  ar_coeff <- list()
  
  eps_new <- matrix(rnorm(T*n,0,1),T,n) ## this eps will be used to be passed through our resulting estimating for Y in order to get infos on the cov matrix
  
  for(i.pass in 1:length(lambda.seq.2ndpass)){ ## for every lambda
    
    # print(c(i.cv, i.pass))
    
    ind_leftout <- c()
    
    beta_roi <- rep(0,ncol(X.full))
    
    ind_full_roi <- 1:length(Y)
    
    ind_leftout  <- ind_full_roi[sort(rep((0:(n-1))*(T-maxlag), length(leftout_rand))) + rep(leftout_rand, n)] ## split in-sample and out-of-sample
    ind_full_roi <- ind_full_roi[-(sort(rep((0:(n-1))*(T-maxlag), length(leftout_rand))) + rep(leftout_rand, n))]
    
    
    X.full.train <- X.full[ind_full_roi, ]
    Y.new.train <- (Y.new[ind_full_roi])
    
    
    get.zero <- which(colMeans(X.full.train[,]) == 0) ## in the case we will have some 0 value rows due to the cv split
    
    if (length(get.zero) != 0) { ## if we actually have some x.cp which only have ones in the test set and not in the train set, we artificially set one t to 1, to avoid solver problems
      # print("problems!")
      # break
      X.full.train[nrow(X.full.train),get.zero] <- 1
      n.CP <- ncol(X.full.train) - length(get.zero)
      get.zero <- c()
    }
    
    
    ## Setup the solver constraint, i.e. no equality constraints, all beta must be smaller 1 but greater 0 and the sum is always smaller than 1
    
    Aeq <- matrix(, 0, ncol(X.full)) # equality constraints
    beq <- rep(0, 0) # Aeq*beta=beq
    # inequality constraints
    # A*beta=b
    sum_condition <- matrix(0, n, ncol(X.full)) # sum condition, each row sum is smaller than 1
    for(k in 1:n){
      sum_condition[k, ncol(X.temp_ar) + ((k-1)*(ncol(X.W)/n) + 1):((k-1)*(ncol(X.W)/n) + n - 1)] <- rep(1, n-1)
    }
    A <- rbind(sum_condition, # condition that each row of W sum to a value smaller than one
               diag(ncol(X.full.train))[(ncol(X.temp_ar)+1):(ncol(X.temp_ar) + ncol(X.W)),], # all w smaller than 1
               -diag(ncol(X.full.train))[(ncol(X.temp_ar)+1):(ncol(X.temp_ar) + ncol(X.W)),]) # all w greater than 0
    b <- matrix(c(rep(1, n), rep(1, ncol(X.W)), rep(0,  ncol(X.W))), 1, nrow(A))
    
    lam_adj <- nrow(X.full.train)*lambda.seq.2ndpass[i.pass] # c(rep(nrow(X.full.train)*lambda.seq.2ndpass[i.pass], maxlag), rep(nrow(X.full.train)*lambda.seq.2ndpass[i.pass], n-1))
    
    res <- solver_func_difflam(X.full.train, Y.new.train, lam_adj, Aeq, beq, A, b)
    
  
    
    
    beta.full <- res
    
    beta_final   <- beta.full[-(1:ncol(X.temp_ar))]  ## delete the betas which correspond to AR term
    beta.ar      <- beta.full[1:ncol(X.temp_ar)] ## get the betas which correspond to AR term
    beta.regr    <- beta.full[(ncol(X.W) + ncol(X.temp_ar) + 1):(ncol(X.W) + ncol(X.temp_ar) + ncol(X.regr))] ## get the betas which correspond to the regressors
    W_est_lasso <- matrix(, n, n)
    diag(W_est_lasso) <- 0 ## to avoid self dependency
    
    est.mean.final        <- matrix(X.temp_ar %*% beta.ar + X.regr %*% beta.regr, T-maxlag, n)  ## allocate so that we do not mix betas of different n
    
    
    
    for (i in 1:n) {
      W_est_lasso[i, which(is.na(W_est_lasso[i, ]))] <- beta_final[1:(n - 1) + (i - 1) * (n - 1)]
    }
    
    new_est <- t(solve(diag(n) - W_est_lasso)%*%t(eps_new)) ## important: we flush the new simulated errors through our estimated w to receive a new sample
    new_real <- Y.mat - t(solve(diag(n) - W_est_lasso)%*%t(est.mean.final)) ## important: we demean the true series Y.mat; if and only if a and w are estimated perfectly, the cor of new_est and new_real must be identical!
    
    cor_est <- cor(new_est)
    cor_real <- cor(new_real)
    
    rmse_vec[i.pass] <- mean((Y.new[ind_leftout] - X.full[ind_leftout, ] %*% beta.full)^2)
    cor_err[i.pass] <- mean(abs(cor_est-cor_real))
    
    w_est[[i.pass]] <- W_est_lasso 
    a_est[[i.pass]] <- est.mean.final
    ar_coeff[[i.pass]] <- beta.ar
    beta_coeff[[i.pass]] <- beta.regr
    
  } ## end loop over the lambdas
  
  rmse_mat[,i.cv] <- rmse_vec
  cor_err_mat[,i.cv] <- cor_err
  
  a_est_list[[i.cv]] <- a_est
  w_est_list[[i.cv]] <- w_est
  ar_coeff_list[[i.cv]] <- ar_coeff
  
  
} ## end loop over the cv iterations


cor_means <- apply(cor_err_mat,1,mean) ## get the means of the error in the cor
rmse_means <- apply(rmse_mat,1,mean) ## get the means of the error in the cor

plot(rmse_means, lwd = 2)
plot(cor_means, lwd = 2)

decision <- which.min(rmse_means) ## which lambda had the least cor err

pos <- decision

## reconstruct the estimates for w by averaging

w_test <- list()

for(j in 1:length(lambda.seq.2ndpass)){
  w_full <- matrix(0,n,n)
  for(i in 1:length(w_est_list)){
    w_full <- w_full + w_est_list[[i]][[j]]
  }
  w_test[[j]] <- w_full/length(w_est_list) ## mean
}
```
:::

::: {.cell layout-align="center"}

```{.r .cell-code}
W_est_lasso <- w_test[[decision]] ## take the best model according to the mean cor error

image(Matrix(round(W_est_lasso, 8), sparse = TRUE))

names <- Data_full$Agrarian_SubRegion[1:n]

apply(W_est_lasso, 1, sum)

# create a network object
network <- tibble(
  from = names[which(round(W_est_lasso, 5) > 0, arr.ind = TRUE)[,1]],
  to = names[which(round(W_est_lasso, 5) > 0, arr.ind = TRUE)[,2]]
)

edges <- which(round(W_est_lasso, 5) > 0, arr.ind = TRUE)

g1 <- graph(edges=as.vector(t(edges)), n = dim(W_est_lasso)[1], directed = TRUE) 
E(g1)$width <- round(W_est_lasso[edges], 3) * 100
V(g1)$label <- names

plot(g1)
```
:::


-->
<p>Purely spatial models:</p>
<p><span class="citation" data-cites="merk2022estimation">Merk and Otto (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span> suggested an adaptive LASSO procedure based on cross-sectional resampling (exploiting the assumption locally constraint spatial dependence)</p>
</div>
<div class="fragment">
<p>Generalised method-of-moment (GMM) estimators are often applied in spatial econometrics because of their (computational) advantages compared to ML estimators</p>
<ul>
<li>Selection of the correct moment conditions via penalised GMM estimators</li>
</ul>
</div>
</section></section>
<section>
<section id="conclusion" class="title-slide slide level1 center" data-number="5">
<h1><span class="header-section-number">5</span> Conclusion</h1>
<ul>
<li>Caution when observations are ordered in time and/or space <span class="math inline">\(\leadsto\)</span> data is probably dependent</li>
<li>Account for this inherent temporal/spatiotemporal dependence in 
<ul>
<li>statistical model (i.e., time-series models, spatiotemporal models, etc.)</li>
<li>cross-validation scheme</li>
<li>bootstrap sampling procedures</li>
<li></li>
</ul></li>
</ul>
<div class="fragment">
<ul>
<li>To avoid computationally complex operations, regularised methods can be considered, e.g., for 
<ul>
<li>model selection (i.e., which covariates/features should be included)</li>
<li>dimensionality reduction of covariance matrices</li>
<li>estimation of sparse temporal/spatial interactions</li>
<li>functional smoothing</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>There is always a bias-variance tradeoff</li>
</ul>
</div>
</section>
<section id="section-15" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div style="margin-top: 100px;">
<p>Thank you for your attention</p>
</div>
</section>
<section id="section-16" class="slide level2 unnumbered" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<div style="margin-top: 200px; font-size: 2em; color: #26351C;">
<p>Thank you for your attention</p>
</div>
<p><a href="https:/philot789.github.io">philot789.github.io</a></p>
</section>
<section class="slide level2 smaller scrollable" id="references">


<img src="logo_luh.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p>Philipp Otto (Leibniz University Hannover)</p>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-ahrens2015two" class="csl-entry" role="doc-biblioentry">
Ahrens, Achim, and Arnab Bhattacharjee. 2015. <span>Two-Step Lasso Estimation of the Spatial Weights Matrix.</span> <em>Econometrics</em> 3 (1): 12855.
</div>
<div id="ref-banerjee2008gaussian" class="csl-entry" role="doc-biblioentry">
Banerjee, Sudipto, Alan E Gelfand, Andrew O Finley, and Huiyan Sang. 2008. <span>Gaussian Predictive Process Models for Large Spatial Data Sets.</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 70 (4): 82548.
</div>
<div id="ref-bhattacharjee2013estimation" class="csl-entry" role="doc-biblioentry">
Bhattacharjee, Arnab, and Chris Jensen-Butler. 2013. <span>Estimation of the Spatial Weights Matrix Under Structural Constraints.</span> <em>Regional Science and Urban Economics</em> 43 (4): 61734.
</div>
<div id="ref-BoonstraEtAl2015" class="csl-entry" role="doc-biblioentry">
Boonstra, Philip S, Bhramar Mukherjee, and Jeremy MG Taylor. 2015. <span>A Small-Sample Choice of the Tuning Parameter in Ridge Regression.</span> Journal Article. <em>Statistica Sinica</em> 25 (3): 1185.
</div>
<div id="ref-chang2010semiparametric" class="csl-entry" role="doc-biblioentry">
Chang, Ya-Mei, Nan-Jung Hsu, and Hsin-Cheng Huang. 2010. <span>Semiparametric Estimation and Selection for Nonstationary Spatial Covariance Functions.</span> <em>Journal of Computational and Graphical Statistics</em> 19 (1): 11739.
</div>
<div id="ref-cressie2008fixed" class="csl-entry" role="doc-biblioentry">
Cressie, Noel, and Gardar Johannesson. 2008. <span>Fixed Rank Kriging for Very Large Spatial Data Sets.</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 70 (1): 20926.
</div>
<div id="ref-cressie2010fixed" class="csl-entry" role="doc-biblioentry">
Cressie, Noel, Tao Shi, and Emily L Kang. 2010. <span>Fixed Rank Filtering for Spatio-Temporal Data.</span> <em>Journal of Computational and Graphical Statistics</em> 19 (3): 72445.
</div>
<div id="ref-Cressie11" class="csl-entry" role="doc-biblioentry">
Cressie, Noel, and Christopher K Wikle. 2011. <em><span class="nocase">Statistics for Spatio-Temporal Data</span></em>. Wiley.
</div>
<div id="ref-Elhorst10" class="csl-entry" role="doc-biblioentry">
Elhorst, J Paul. 2010. <span><span class="nocase">Applied Spatial Econometrics: Raising the Bar</span>.</span> <em>Spatial Economic Analysis</em> 5 (1): 928. <a href="https://doi.org/10.1080/17421770903541772">https://doi.org/10.1080/17421770903541772</a>.
</div>
<div id="ref-fisher1935design" class="csl-entry" role="doc-biblioentry">
Fisher, Ronald A. 1935. <span>The Design of Experiments.</span> <em>Oliver and Boyd, Edinburgh</em>.
</div>
<div id="ref-furrer2016asymptotic" class="csl-entry" role="doc-biblioentry">
Furrer, Reinhard, Franois Bachoc, and Juan Du. 2016. <span>Asymptotic Properties of Multivariate Tapering for Estimation and Prediction.</span> <em>Journal of Multivariate Analysis</em> 149: 17791.
</div>
<div id="ref-furrer2007estimation" class="csl-entry" role="doc-biblioentry">
Furrer, Reinhard, and Thomas Bengtsson. 2007. <span>Estimation of High-Dimensional Prior and Posterior Covariance Matrices in <span>Kalman</span> Filter Variants.</span> <em>Journal of Multivariate Analysis</em> 98 (2): 22755.
</div>
<div id="ref-furrer2006covariance" class="csl-entry" role="doc-biblioentry">
Furrer, Reinhard, Marc G Genton, and Douglas Nychka. 2006. <span>Covariance Tapering for Interpolation of Large Spatial Datasets.</span> <em>Journal of Computational and Graphical Statistics</em> 15 (3): 50223.
</div>
<div id="ref-gibbons2012mostly" class="csl-entry" role="doc-biblioentry">
Gibbons, Stephen, and Henry G Overman. 2012. <span>Mostly Pointless Spatial Econometrics?</span> <em>Journal of Regional Science</em> 52 (2): 17291.
</div>
<div id="ref-gonella2022facing" class="csl-entry" role="doc-biblioentry">
Gonella, Romina, Mathias Bourel, and Liliane Bel. 2022. <span>Facing Spatial Massive Data in Science and Society: Variable Selection for Spatial Models.</span> <em>Spatial Statistics</em>, 100627.
</div>
<div id="ref-hsiang1975bayesian" class="csl-entry" role="doc-biblioentry">
Hsiang, TC. 1975. <span>A Bayesian View on Ridge Regression.</span> <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em> 24 (4): 26768.
</div>
<div id="ref-hsu2012group" class="csl-entry" role="doc-biblioentry">
Hsu, Nan-Jung, Ya-Mei Chang, and Hsin-Cheng Huang. 2012. <span>A Group Lasso Approach for Non-Stationary SpatialTemporal Covariance Estimation.</span> <em>Environmetrics</em> 23 (1): 1223.
</div>
<div id="ref-JiangWang2017" class="csl-entry" role="doc-biblioentry">
Jiang, Gaoxia, and Wenjian Wang. 2017. <span>Markov Cross-Validation for Time Series Model Evaluations.</span> Journal Article. <em>Information Sciences</em> 375: 21933. https://doi.org/<a href="https://doi.org/10.1016/j.ins.2016.09.061">https://doi.org/10.1016/j.ins.2016.09.061</a>.
</div>
<div id="ref-kang2021correlation" class="csl-entry" role="doc-biblioentry">
Kang, Myeongjong, and Matthias Katzfuss. 2021. <span>Correlation-Based Sparse Inverse <span>Cholesky</span> Factorization for Fast <span>Gaussian</span>-Process Inference.</span> <em>arXiv Preprint arXiv:2112.14591</em>.
</div>
<div id="ref-kaufman2008covariance" class="csl-entry" role="doc-biblioentry">
Kaufman, Cari G, Mark J Schervish, and Douglas W Nychka. 2008. <span>Covariance Tapering for Likelihood-Based Estimation in Large Spatial Data Sets.</span> <em>Journal of the American Statistical Association</em> 103 (484): 154555.
</div>
<div id="ref-kolaczyk2010network" class="csl-entry" role="doc-biblioentry">
Kolaczyk, Eric D. 2010. <em>Statistical Analysis of Network Data: Methods and Models</em>. Springer.
</div>
<div id="ref-kolaczyk2014statistical" class="csl-entry" role="doc-biblioentry">
Kolaczyk, Eric D, and Gbor Csrdi. 2014. <em>Statistical Analysis of Network Data with <span>R</span></em>. Springer.
</div>
<div id="ref-kostov2010model" class="csl-entry" role="doc-biblioentry">
Kostov, Philip. 2010. <span>Model Boosting for Spatial Weighting Matrix Selection in Spatial Lag Models.</span> <em>Environment and Planning B: Planning and Design</em> 37 (3): 53349.
</div>
<div id="ref-kostov2013spatial" class="csl-entry" role="doc-biblioentry">
Kostov, Phillip. 2013. <span>Spatial Weighting Matrix Selection in Spatial Lag Econometric Model.</span> <em>Econometrics</em> 1 (1): 2030.
</div>
<div id="ref-krock2021nonstationary" class="csl-entry" role="doc-biblioentry">
Krock, Mitchell, William Kleiber, and Stephen Becker. 2021. <span>Nonstationary Modeling with Sparsity for Spatial Data via the Basis Graphical Lasso.</span> <em>Journal of Computational and Graphical Statistics</em> 30 (2): 37589.
</div>
<div id="ref-krock2021modeling" class="csl-entry" role="doc-biblioentry">
Krock, Mitchell, William Kleiber, Dorit Hammerling, and Stephen Becker. 2021. <span>Modeling Massive Highly-Multivariate Nonstationary Spatial Data with the Basis Graphical Lasso.</span> <em>arXiv Preprint arXiv:2101.02404</em>.
</div>
<div id="ref-lam2020estimation" class="csl-entry" role="doc-biblioentry">
Lam, Clifford, and Pedro CL Souza. 2020. <span>Estimation and Selection of Spatial Weight Matrix in a Spatial Lag Model.</span> <em>Journal of Business &amp; Economic Statistics</em> 38 (3): 693710.
</div>
<div id="ref-liu2018penalized" class="csl-entry" role="doc-biblioentry">
Liu, Xuan, Jianbao Chen, and Suli Cheng. 2018. <span>A Penalized Quasi-Maximum Likelihood Method for Variable Selection in the Spatial Autoregressive Model.</span> <em>Spatial Statistics</em> 25: 86104.
</div>
<div id="ref-manski1993identification" class="csl-entry" role="doc-biblioentry">
Manski, Charles F. 1993. <span>Identification of Endogenous Social Effects: The Reflection Problem.</span> <em>The Review of Economic Studies</em> 60 (3): 53142.
</div>
<div id="ref-merk2021directional" class="csl-entry" role="doc-biblioentry">
Merk, Miryam S, and Philipp Otto. 2021. <span>Directional Spatial Autoregressive Dependence in the Conditional First-and Second-Order Moments.</span> <em>Spatial Statistics</em> 41: 100490.
</div>
<div id="ref-merk2022estimation" class="csl-entry" role="doc-biblioentry">
. 2022. <span>Estimation of the Spatial Weighting Matrix for Regular Lattice Dataan Adaptive Lasso Approach with Cross-Sectional Resampling.</span> <em>Environmetrics</em> 33 (1): e2705.
</div>
<div id="ref-otto2022estimation" class="csl-entry" role="doc-biblioentry">
Otto, Philipp, and Rick Steinert. 2022. <span>Estimation of the Spatial Weighting Matrix for Spatiotemporal Data Under the Presence of Structural Breaks.</span> <em>Journal of Computational and Graphical Statistics</em>, no. just-accepted: 144.
</div>
<div id="ref-park2008bayesian" class="csl-entry" role="doc-biblioentry">
Park, Trevor, and George Casella. 2008. <span>The Bayesian Lasso.</span> <em>Journal of the American Statistical Association</em> 103 (482): 68186.
</div>
<div id="ref-rue2017bayesian" class="csl-entry" role="doc-biblioentry">
Rue, Hvard, Andrea Riebler, Sigrunn H Srbye, Janine B Illian, Daniel P Simpson, and Finn K Lindgren. 2017. <span>Bayesian Computing with <span>INLA</span>: A Review.</span> <em>Annual Review of Statistics and Its Application</em> 4: 395421.
</div>
<div id="ref-saha2021random" class="csl-entry" role="doc-biblioentry">
Saha, Arkajyoti, Sumanta Basu, and Abhirup Datta. 2021. <span>Random Forests for Spatially Dependent Data.</span> <em>Journal of the American Statistical Association</em>, 119.
</div>
<div id="ref-schaefer2021sparse" class="csl-entry" role="doc-biblioentry">
Schfer, Florian, Matthias Katzfuss, and Houman Owhadi. 2021. <span>Sparse <span>Cholesky</span> Factorization by <span>KullbackLeibler</span> Minimization.</span> <em>SIAM Journal on Scientific Computing</em> 43 (3): A201946.
</div>
<div id="ref-stein2013statistical" class="csl-entry" role="doc-biblioentry">
Stein, Michael L. 2013. <span>Statistical Properties of Covariance Tapers.</span> <em>Journal of Computational and Graphical Statistics</em> 22 (4): 86685.
</div>
<div id="ref-stein2004approximating" class="csl-entry" role="doc-biblioentry">
Stein, Michael L, Zhiyi Chi, and Leah J Welty. 2004. <span>Approximating Likelihoods for Large Spatial Data Sets.</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 66 (2): 27596.
</div>
<div id="ref-Tobler70" class="csl-entry" role="doc-biblioentry">
Tobler, Waldo R. 1970. <span>A Computer Movie Simulating Urban Growth in the <span>Detroit</span> Region.</span> <em>Economic Geography</em> 46 (sup1): 23440.
</div>
<div id="ref-van2019shrinkage" class="csl-entry" role="doc-biblioentry">
Van Erp, Sara, Daniel L Oberski, and Joris Mulder. 2019. <span>Shrinkage Priors for Bayesian Penalized Regression.</span> <em>Journal of Mathematical Psychology</em> 89: 3150.
</div>
<div id="ref-vecchia1988estimation" class="csl-entry" role="doc-biblioentry">
Vecchia, Aldo V. 1988. <span>Estimation and Model Identification for Continuous Spatial Processes.</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 50 (2): 297312.
</div>
<div id="ref-Zhu10" class="csl-entry" role="doc-biblioentry">
Zhu, Jun, Hsin-Cheng Huang, and Perla E Reyes. 2010. <span>On Selection of Spatial Linear Models for Lattice Data.</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 72 (3): 389402.
</div>
<div id="ref-zhu2009estimating" class="csl-entry" role="doc-biblioentry">
Zhu, Zhengyuan, and Yufeng Liu. 2009. <span>Estimating Spatial Covariance Using Penalised Likelihood with Weighted <span class="math inline">\(L_1\)</span> Penalty.</span> <em>Journal of Nonparametric Statistics</em> 21 (7): 92542.
</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="ShortCourse_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="ShortCourse_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="ShortCourse_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="ShortCourse_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"theme":"chalkboard"},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>